{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e7d4675",
   "metadata": {},
   "source": [
    "# AutoGluon Tabular - Essential Functionality\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/autogluon/autogluon/blob/master/docs/tutorials/tabular/tabular-essentials.ipynb)\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/autogluon/autogluon/blob/master/docs/tutorials/tabular/tabular-essentials.ipynb)\n",
    "\n",
    "\n",
    "Via a simple `fit()` call, AutoGluon can produce highly-accurate models to predict the values in one column of a data table based on the rest of the columns' values. Use AutoGluon with tabular data for both classification and regression problems. This tutorial demonstrates how to use AutoGluon to produce a classification model that predicts whether or not a person's income exceeds $50,000.\n",
    "\n",
    "## TabularPredictor\n",
    "\n",
    "To start, import AutoGluon's [TabularPredictor](../../api/autogluon.tabular.TabularPredictor.rst) and [TabularDataset](../../api/autogluon.core.TabularDataset.rst) classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa00faab-252f-44c9-b8f7-57131aa8251c",
   "metadata": {
    "tags": [
     "remove-cell"
    ],
    "ExecuteTime": {
     "end_time": "2023-12-27T06:32:22.951919Z",
     "start_time": "2023-12-27T06:32:22.946126Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install autogluon.tabular[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b48e2768",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T06:32:55.843817Z",
     "start_time": "2023-12-27T06:32:55.761290Z"
    }
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef2fc39",
   "metadata": {},
   "source": [
    "Load training data from a [CSV file](https://en.wikipedia.org/wiki/Comma-separated_values) into an AutoGluon Dataset object. This object is essentially equivalent to a [Pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) and the same methods can be applied to both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "671f5ff7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T06:33:01.817062Z",
     "start_time": "2023-12-27T06:32:56.882680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       age workclass  fnlwgt      education  education-num  \\\n6118    51   Private   39264   Some-college             10   \n23204   58   Private   51662           10th              6   \n29590   40   Private  326310   Some-college             10   \n18116   37   Private  222450        HS-grad              9   \n33964   62   Private  109190      Bachelors             13   \n\n            marital-status        occupation    relationship    race      sex  \\\n6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n23204   Married-civ-spouse     Other-service            Wife   White   Female   \n29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n18116        Never-married             Sales   Not-in-family   White     Male   \n33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n\n       capital-gain  capital-loss  hours-per-week  native-country   class  \n6118              0             0              40   United-States    >50K  \n23204             0             0               8   United-States   <=50K  \n29590             0             0              44   United-States   <=50K  \n18116             0          2339              40     El-Salvador   <=50K  \n33964         15024             0              40   United-States    >50K  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6118</th>\n      <td>51</td>\n      <td>Private</td>\n      <td>39264</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>23204</th>\n      <td>58</td>\n      <td>Private</td>\n      <td>51662</td>\n      <td>10th</td>\n      <td>6</td>\n      <td>Married-civ-spouse</td>\n      <td>Other-service</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>29590</th>\n      <td>40</td>\n      <td>Private</td>\n      <td>326310</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Married-civ-spouse</td>\n      <td>Craft-repair</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>44</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>18116</th>\n      <td>37</td>\n      <td>Private</td>\n      <td>222450</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Never-married</td>\n      <td>Sales</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>2339</td>\n      <td>40</td>\n      <td>El-Salvador</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>33964</th>\n      <td>62</td>\n      <td>Private</td>\n      <td>109190</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>15024</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac3f9f5",
   "metadata": {},
   "source": [
    "Note that we loaded data from a CSV file stored in the cloud. You can also specify a local file-path instead if you have already downloaded the CSV file to your own machine (e.g., using [wget](https://www.gnu.org/software/wget/)).\n",
    "Each row in the table `train_data` corresponds to a single training example. In this particular dataset, each row corresponds to an individual person, and the columns contain various characteristics reported during a census.\n",
    "\n",
    "Let's first use these features to predict whether the person's income exceeds $50,000 or not, which is recorded in the `class` column of this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fbae4f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T06:33:01.846563Z",
     "start_time": "2023-12-27T06:33:01.779508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes: [' >50K', ' <=50K']\n"
     ]
    }
   ],
   "source": [
    "label = 'class'\n",
    "print(f\"Unique classes: {list(train_data[label].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2808c11",
   "metadata": {},
   "source": [
    "AutoGluon works with raw data, meaning you don't need to perform any data preprocessing before fitting AutoGluon. We actively recommend that you avoid performing operations such as missing value imputation or one-hot-encoding, as AutoGluon has dedicated logic to handle these situations automatically. You can learn more about AutoGluon's preprocessing in the [Feature Engineering Tutorial](tabular-feature-engineering.ipynb).\n",
    "\n",
    "### Training\n",
    "\n",
    "Now we initialize and fit AutoGluon's TabularPredictor in one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93ed52d4",
   "metadata": {
    "tags": [
     "hide-output"
    ],
    "ExecuteTime": {
     "end_time": "2023-12-27T06:34:12.351759Z",
     "start_time": "2023-12-27T06:33:01.790832Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231227_063301\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231227_063301\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 23.2.0: Wed Nov 15 21:54:10 PST 2023; root:xnu-10002.61.3~2/RELEASE_X86_64\n",
      "CPU Count:          16\n",
      "Memory Avail:       46.81 GB / 64.00 GB (73.1%)\n",
      "Disk Space Avail:   455.43 GB / 931.55 GB (48.9%)\n",
      "===================================================\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column:       class\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' >50K', ' <=50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    47931.57 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.3s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.32s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.73\t = Validation score   (accuracy)\n",
      "\t9.52s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.65\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t5.27s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t3.51s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t1.17s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t1.03s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t1.55s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.82\t = Validation score   (accuracy)\n",
      "\t1.11s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.81\t = Validation score   (accuracy)\n",
      "\t1.09s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.82\t = Validation score   (accuracy)\n",
      "\t4.41s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.87\t = Validation score   (accuracy)\n",
      "\t5.35s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t4.31s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t28.9s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'XGBoost': 1.0}\n",
      "\t0.87\t = Validation score   (accuracy)\n",
      "\t1.55s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 70.47s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231227_063301\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label).fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1088b80f",
   "metadata": {},
   "source": [
    "That's it! We now have a TabularPredictor that is able to make predictions on new data.\n",
    "\n",
    "### Prediction\n",
    "\n",
    "Next, load separate test data to demonstrate how to make predictions on new examples at inference time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38907743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T06:34:13.901462Z",
     "start_time": "2023-12-27T06:34:12.377674Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n"
     ]
    },
    {
     "data": {
      "text/plain": "   age          workclass  fnlwgt      education  education-num  \\\n0   31            Private  169085           11th              7   \n1   17   Self-emp-not-inc  226203           12th              8   \n2   47            Private   54260      Assoc-voc             11   \n3   21            Private  176262   Some-college             10   \n4   17            Private  241185           12th              8   \n\n        marital-status        occupation relationship    race      sex  \\\n0   Married-civ-spouse             Sales         Wife   White   Female   \n1        Never-married             Sales    Own-child   White     Male   \n2   Married-civ-spouse   Exec-managerial      Husband   White     Male   \n3        Never-married   Exec-managerial    Own-child   White   Female   \n4        Never-married    Prof-specialty    Own-child   White     Male   \n\n   capital-gain  capital-loss  hours-per-week  native-country   class  \n0             0             0              20   United-States   <=50K  \n1             0             0              45   United-States   <=50K  \n2             0          1887              60   United-States    >50K  \n3             0             0              30   United-States   <=50K  \n4             0             0              20   United-States   <=50K  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>31</td>\n      <td>Private</td>\n      <td>169085</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Married-civ-spouse</td>\n      <td>Sales</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17</td>\n      <td>Self-emp-not-inc</td>\n      <td>226203</td>\n      <td>12th</td>\n      <td>8</td>\n      <td>Never-married</td>\n      <td>Sales</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>45</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47</td>\n      <td>Private</td>\n      <td>54260</td>\n      <td>Assoc-voc</td>\n      <td>11</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>1887</td>\n      <td>60</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21</td>\n      <td>Private</td>\n      <td>176262</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Never-married</td>\n      <td>Exec-managerial</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>Private</td>\n      <td>241185</td>\n      <td>12th</td>\n      <td>8</td>\n      <td>Never-married</td>\n      <td>Prof-specialty</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bd6e65",
   "metadata": {},
   "source": [
    "We can now use our trained models to make predictions on the new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "388da91b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T06:34:14.213116Z",
     "start_time": "2023-12-27T06:34:13.904400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0     <=50K\n1     <=50K\n2     <=50K\n3     <=50K\n4     <=50K\nName: class, dtype: object"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data)\n",
    "y_pred.head()  # Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "      <=50K      >50K\n0  0.982107  0.017893\n1  0.988337  0.011663\n2  0.573505  0.426495\n3  0.998272  0.001728\n4  0.990299  0.009701",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>&lt;=50K</th>\n      <th>&gt;50K</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.982107</td>\n      <td>0.017893</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.988337</td>\n      <td>0.011663</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.573505</td>\n      <td>0.426495</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.998272</td>\n      <td>0.001728</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.990299</td>\n      <td>0.009701</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = predictor.predict_proba(test_data)\n",
    "y_pred_proba.head()  # Prediction Probabilities"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:34:14.343852Z",
     "start_time": "2023-12-27T06:34:14.083195Z"
    }
   },
   "id": "1f2ea44baed01439"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation\n",
    "\n",
    "Next, we can [evaluate](../../api/autogluon.tabular.TabularPredictor.evaluate.rst) the predictor on the (labeled) test data:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1ac16b755097c93"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'accuracy': 0.8374449790152523,\n 'balanced_accuracy': 0.7430558394221018,\n 'mcc': 0.5243657567117436,\n 'roc_auc': 0.8807467921857952,\n 'f1': 0.621904761904762,\n 'precision': 0.69394261424017,\n 'recall': 0.5634167385677308}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:34:14.583044Z",
     "start_time": "2023-12-27T06:34:14.219490Z"
    }
   },
   "id": "ccfb48acf364b609"
  },
  {
   "cell_type": "markdown",
   "id": "ec141019",
   "metadata": {},
   "source": [
    "We can also [evaluate each model individually](../../api/autogluon.tabular.TabularPredictor.leaderboard.rst):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0630d00d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T06:34:16.902848Z",
     "start_time": "2023-12-27T06:34:14.451851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                  model  score_test  score_val eval_metric  pred_time_test  \\\n0      RandomForestGini    0.842768       0.84    accuracy        0.219860   \n1              CatBoost    0.842461       0.85    accuracy        0.031345   \n2      RandomForestEntr    0.841437       0.83    accuracy        0.227978   \n3              LightGBM    0.839799       0.85    accuracy        0.024909   \n4               XGBoost    0.837445       0.87    accuracy        0.066089   \n5   WeightedEnsemble_L2    0.837445       0.87    accuracy        0.069151   \n6            LightGBMXT    0.836421       0.83    accuracy        0.020228   \n7        ExtraTreesGini    0.833760       0.82    accuracy        0.236868   \n8        NeuralNetTorch    0.833555       0.83    accuracy        0.170405   \n9        ExtraTreesEntr    0.832941       0.81    accuracy        0.217202   \n10        LightGBMLarge    0.828949       0.83    accuracy        0.030148   \n11      NeuralNetFastAI    0.818610       0.82    accuracy        0.348275   \n12       KNeighborsUnif    0.725970       0.73    accuracy        0.040771   \n13       KNeighborsDist    0.695158       0.65    accuracy        0.042237   \n\n    pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n0        0.108663   1.170013                 0.219860                0.108663   \n1        0.010876   1.546031                 0.031345                0.010876   \n2        0.116711   1.030677                 0.227978                0.116711   \n3        0.010401   3.506808                 0.024909                0.010401   \n4        0.016668   5.354931                 0.066089                0.016668   \n5        0.018323   6.901716                 0.003062                0.001655   \n6        0.014280   5.272942                 0.020228                0.014280   \n7        0.110902   1.105237                 0.236868                0.110902   \n8        0.023762   4.305347                 0.170405                0.023762   \n9        0.120091   1.091037                 0.217202                0.120091   \n10       0.011278  28.901503                 0.030148                0.011278   \n11       0.033405   4.405574                 0.348275                0.033405   \n12       0.092124   9.518981                 0.040771                0.092124   \n13       0.308882   0.018585                 0.042237                0.308882   \n\n    fit_time_marginal  stack_level  can_infer  fit_order  \n0            1.170013            1       True          5  \n1            1.546031            1       True          7  \n2            1.030677            1       True          6  \n3            3.506808            1       True          4  \n4            5.354931            1       True         11  \n5            1.546785            2       True         14  \n6            5.272942            1       True          3  \n7            1.105237            1       True          8  \n8            4.305347            1       True         12  \n9            1.091037            1       True          9  \n10          28.901503            1       True         13  \n11           4.405574            1       True         10  \n12           9.518981            1       True          1  \n13           0.018585            1       True          2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RandomForestGini</td>\n      <td>0.842768</td>\n      <td>0.84</td>\n      <td>accuracy</td>\n      <td>0.219860</td>\n      <td>0.108663</td>\n      <td>1.170013</td>\n      <td>0.219860</td>\n      <td>0.108663</td>\n      <td>1.170013</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CatBoost</td>\n      <td>0.842461</td>\n      <td>0.85</td>\n      <td>accuracy</td>\n      <td>0.031345</td>\n      <td>0.010876</td>\n      <td>1.546031</td>\n      <td>0.031345</td>\n      <td>0.010876</td>\n      <td>1.546031</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForestEntr</td>\n      <td>0.841437</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.227978</td>\n      <td>0.116711</td>\n      <td>1.030677</td>\n      <td>0.227978</td>\n      <td>0.116711</td>\n      <td>1.030677</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LightGBM</td>\n      <td>0.839799</td>\n      <td>0.85</td>\n      <td>accuracy</td>\n      <td>0.024909</td>\n      <td>0.010401</td>\n      <td>3.506808</td>\n      <td>0.024909</td>\n      <td>0.010401</td>\n      <td>3.506808</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>XGBoost</td>\n      <td>0.837445</td>\n      <td>0.87</td>\n      <td>accuracy</td>\n      <td>0.066089</td>\n      <td>0.016668</td>\n      <td>5.354931</td>\n      <td>0.066089</td>\n      <td>0.016668</td>\n      <td>5.354931</td>\n      <td>1</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>0.837445</td>\n      <td>0.87</td>\n      <td>accuracy</td>\n      <td>0.069151</td>\n      <td>0.018323</td>\n      <td>6.901716</td>\n      <td>0.003062</td>\n      <td>0.001655</td>\n      <td>1.546785</td>\n      <td>2</td>\n      <td>True</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LightGBMXT</td>\n      <td>0.836421</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.020228</td>\n      <td>0.014280</td>\n      <td>5.272942</td>\n      <td>0.020228</td>\n      <td>0.014280</td>\n      <td>5.272942</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ExtraTreesGini</td>\n      <td>0.833760</td>\n      <td>0.82</td>\n      <td>accuracy</td>\n      <td>0.236868</td>\n      <td>0.110902</td>\n      <td>1.105237</td>\n      <td>0.236868</td>\n      <td>0.110902</td>\n      <td>1.105237</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>NeuralNetTorch</td>\n      <td>0.833555</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.170405</td>\n      <td>0.023762</td>\n      <td>4.305347</td>\n      <td>0.170405</td>\n      <td>0.023762</td>\n      <td>4.305347</td>\n      <td>1</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ExtraTreesEntr</td>\n      <td>0.832941</td>\n      <td>0.81</td>\n      <td>accuracy</td>\n      <td>0.217202</td>\n      <td>0.120091</td>\n      <td>1.091037</td>\n      <td>0.217202</td>\n      <td>0.120091</td>\n      <td>1.091037</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>LightGBMLarge</td>\n      <td>0.828949</td>\n      <td>0.83</td>\n      <td>accuracy</td>\n      <td>0.030148</td>\n      <td>0.011278</td>\n      <td>28.901503</td>\n      <td>0.030148</td>\n      <td>0.011278</td>\n      <td>28.901503</td>\n      <td>1</td>\n      <td>True</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>NeuralNetFastAI</td>\n      <td>0.818610</td>\n      <td>0.82</td>\n      <td>accuracy</td>\n      <td>0.348275</td>\n      <td>0.033405</td>\n      <td>4.405574</td>\n      <td>0.348275</td>\n      <td>0.033405</td>\n      <td>4.405574</td>\n      <td>1</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>KNeighborsUnif</td>\n      <td>0.725970</td>\n      <td>0.73</td>\n      <td>accuracy</td>\n      <td>0.040771</td>\n      <td>0.092124</td>\n      <td>9.518981</td>\n      <td>0.040771</td>\n      <td>0.092124</td>\n      <td>9.518981</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>KNeighborsDist</td>\n      <td>0.695158</td>\n      <td>0.65</td>\n      <td>accuracy</td>\n      <td>0.042237</td>\n      <td>0.308882</td>\n      <td>0.018585</td>\n      <td>0.042237</td>\n      <td>0.308882</td>\n      <td>0.018585</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading a Trained Predictor\n",
    "\n",
    "Finally, we can load the predictor in a new session (or new machine) by calling [TabularPredictor.load()](../../api/autogluon.tabular.TabularPredictor.load.rst) and specifying the location of the predictor artifact on disk."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae35bc029d386579"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "'AutogluonModels/ag-20231227_063301'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.path  # The path on disk where the predictor is saved"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:34:16.946972Z",
     "start_time": "2023-12-27T06:34:16.881500Z"
    }
   },
   "id": "85fcbc65e9dd2cfd"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Load the predictor by specifying the path it is saved to on disk.\n",
    "# You can control where it is saved to by setting the `path` parameter during init\n",
    "predictor = TabularPredictor.load(predictor.path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:34:16.992530Z",
     "start_time": "2023-12-27T06:34:16.901777Z"
    }
   },
   "id": "3710a0faca8d4af1"
  },
  {
   "cell_type": "markdown",
   "id": "6a32a595",
   "metadata": {},
   "source": [
    "Now you're ready to try AutoGluon on your own tabular datasets!\n",
    "As long as they're stored in a popular format like CSV, you should be able to achieve strong predictive performance with just 2 lines of code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1650bf",
   "metadata": {},
   "source": [
    "```\n",
    "from autogluon.tabular import TabularPredictor\n",
    "predictor = TabularPredictor(label=<variable-name>).fit(train_data=<file-name>)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255b4558",
   "metadata": {},
   "source": [
    "**Note:** This simple call to [TabularPredictor.fit()](../../api/autogluon.tabular.TabularPredictor.fit.rst) is intended for your first prototype model. In a subsequent section, we'll demonstrate how to maximize predictive performance by additionally specifying the `presets` parameter to `fit()` and the `eval_metric` parameter to `TabularPredictor()`.\n",
    "\n",
    "## Description of fit()\n",
    "\n",
    "Here we discuss what happened during `fit()`.\n",
    "\n",
    "Since there are only two possible values of the `class` variable, this was a binary classification problem, for which an appropriate performance metric is _accuracy_. AutoGluon automatically infers this as well as the type of each feature (i.e., which columns contain continuous numbers vs. discrete categories). AutoGluon can also automatically handle common issues like missing data and rescaling feature values.\n",
    "\n",
    "We did not specify separate validation data and so AutoGluon automatically chose a random training/validation split of the data. The data used for validation is separated from the training data and is used to determine the models and hyperparameter-values that produce the best results. Rather than just a single model, AutoGluon trains multiple models and ensembles them together to obtain superior predictive performance.\n",
    "\n",
    "By default, AutoGluon tries to fit [various types of models](../../api/autogluon.tabular.models.rst) including neural networks and tree ensembles. Each type of model has various hyperparameters, which traditionally, the user would have to specify. AutoGluon automates this process.\n",
    "\n",
    "AutoGluon automatically and iteratively tests values for hyperparameters to produce the best performance on the validation data. This involves repeatedly training models under different hyperparameter settings and evaluating their performance. This process can be computationally-intensive, so `fit()` parallelizes this process across multiple threads using [Ray](https://www.ray.io/). To control runtimes, you can specify various arguments in `fit()` such as `time_limit` as demonstrated in the subsequent **[In-Depth Tutorial](tabular-indepth.ipynb)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f84eca",
   "metadata": {},
   "source": [
    "We can view what properties AutoGluon automatically inferred about our prediction task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4074d3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T06:34:55.078969Z",
     "start_time": "2023-12-27T06:34:55.035288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon infers problem type is:  binary\n",
      "AutoGluon identified the following types of features:\n",
      "('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "('int', ['bool']) : 1 | ['sex']\n"
     ]
    }
   ],
   "source": [
    "print(\"AutoGluon infers problem type is: \", predictor.problem_type)\n",
    "print(\"AutoGluon identified the following types of features:\")\n",
    "print(predictor.feature_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fde02c",
   "metadata": {},
   "source": [
    "AutoGluon correctly recognized our prediction problem to be a **binary classification** task and decided that variables such as `age` should be represented as integers, whereas variables such as `workclass` should be represented as categorical objects. The `feature_metadata` attribute allows you to see the inferred data type of each predictive variable after preprocessing (this is its _raw_ dtype; some features may also be associated with additional _special_ dtypes if produced via feature-engineering, e.g. numerical representations of a datetime/text column)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "To transform the data into AutoGluon's internal representation, we can do the following:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27f0ef525a7db211"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "   age          workclass  fnlwgt      education  education-num  \\\n0   31            Private  169085           11th              7   \n1   17   Self-emp-not-inc  226203           12th              8   \n2   47            Private   54260      Assoc-voc             11   \n3   21            Private  176262   Some-college             10   \n4   17            Private  241185           12th              8   \n\n        marital-status        occupation relationship    race      sex  \\\n0   Married-civ-spouse             Sales         Wife   White   Female   \n1        Never-married             Sales    Own-child   White     Male   \n2   Married-civ-spouse   Exec-managerial      Husband   White     Male   \n3        Never-married   Exec-managerial    Own-child   White   Female   \n4        Never-married    Prof-specialty    Own-child   White     Male   \n\n   capital-gain  capital-loss  hours-per-week  native-country   class  \n0             0             0              20   United-States   <=50K  \n1             0             0              45   United-States   <=50K  \n2             0          1887              60   United-States    >50K  \n3             0             0              30   United-States   <=50K  \n4             0             0              20   United-States   <=50K  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>31</td>\n      <td>Private</td>\n      <td>169085</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Married-civ-spouse</td>\n      <td>Sales</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17</td>\n      <td>Self-emp-not-inc</td>\n      <td>226203</td>\n      <td>12th</td>\n      <td>8</td>\n      <td>Never-married</td>\n      <td>Sales</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>45</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47</td>\n      <td>Private</td>\n      <td>54260</td>\n      <td>Assoc-voc</td>\n      <td>11</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>1887</td>\n      <td>60</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21</td>\n      <td>Private</td>\n      <td>176262</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Never-married</td>\n      <td>Exec-managerial</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>Private</td>\n      <td>241185</td>\n      <td>12th</td>\n      <td>8</td>\n      <td>Never-married</td>\n      <td>Prof-specialty</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:35:35.054156Z",
     "start_time": "2023-12-27T06:35:35.003736Z"
    }
   },
   "id": "f1b83de7ba7b495d"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "   age  fnlwgt  education-num  sex  capital-gain  capital-loss  \\\n0   31  169085              7    0             0             0   \n1   17  226203              8    1             0             0   \n2   47   54260             11    1             0          1887   \n3   21  176262             10    0             0             0   \n4   17  241185              8    1             0             0   \n\n   hours-per-week workclass education marital-status occupation relationship  \\\n0              20         3         1              1         10            5   \n1              45         5         2              3         10            3   \n2              60         3         7              1          3            0   \n3              30         3        13              3          3            3   \n4              20         3         2              3          8            3   \n\n  race native-country  \n0    4             14  \n1    4             14  \n2    4             14  \n3    4             14  \n4    4             14  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>fnlwgt</th>\n      <th>education-num</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>workclass</th>\n      <th>education</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>native-country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>31</td>\n      <td>169085</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>5</td>\n      <td>4</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17</td>\n      <td>226203</td>\n      <td>8</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>45</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>10</td>\n      <td>3</td>\n      <td>4</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47</td>\n      <td>54260</td>\n      <td>11</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1887</td>\n      <td>60</td>\n      <td>3</td>\n      <td>7</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>4</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21</td>\n      <td>176262</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>3</td>\n      <td>13</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>241185</td>\n      <td>8</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>8</td>\n      <td>3</td>\n      <td>4</td>\n      <td>14</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_transform = predictor.transform_features(test_data)\n",
    "test_data_transform.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:38:07.919726Z",
     "start_time": "2023-12-27T06:38:07.837652Z"
    }
   },
   "id": "addae3bd40b4318a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice how the data is purely numeric after pre-processing (although categorical features will still be treated as categorical downstream).\n",
    "\n",
    "To better understand our trained predictor, we can estimate the overall importance of each feature via [TabularPredictor.feature_importance()](../../api/autogluon.tabular.TabularPredictor.feature_importance.rst):"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a608ba782bef998"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 14 features using 5000 rows with 5 shuffle sets...\n",
      "\t4.92s\t= Expected runtime (0.98s per shuffle set)\n",
      "\t5.02s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                importance    stddev       p_value  n  p99_high   p99_low\nmarital-status     0.04992  0.002995  1.548031e-06  5  0.056087  0.043753\neducation-num      0.03192  0.002161  2.507753e-06  5  0.036371  0.027469\ncapital-gain       0.03052  0.002062  2.485369e-06  5  0.034766  0.026274\nage                0.01280  0.003718  7.656432e-04  5  0.020454  0.005146\nhours-per-week     0.01152  0.004582  2.460466e-03  5  0.020954  0.002086\noccupation         0.00476  0.001711  1.700352e-03  5  0.008283  0.001237\nrelationship       0.00344  0.000167  6.697221e-07  5  0.003785  0.003095\nworkclass          0.00184  0.001596  3.074391e-02  5  0.005127 -0.001447\nnative-country     0.00112  0.000795  1.725293e-02  5  0.002757 -0.000517\nsex                0.00112  0.000303  5.869020e-04  5  0.001745  0.000495\neducation          0.00040  0.001030  2.170027e-01  5  0.002520 -0.001720\ncapital-loss       0.00024  0.000555  1.941545e-01  5  0.001383 -0.000903\nrace              -0.00052  0.000807  8.883573e-01  5  0.001143 -0.002183\nfnlwgt            -0.00156  0.002161  9.091426e-01  5  0.002889 -0.006009",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>importance</th>\n      <th>stddev</th>\n      <th>p_value</th>\n      <th>n</th>\n      <th>p99_high</th>\n      <th>p99_low</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>marital-status</th>\n      <td>0.04992</td>\n      <td>0.002995</td>\n      <td>1.548031e-06</td>\n      <td>5</td>\n      <td>0.056087</td>\n      <td>0.043753</td>\n    </tr>\n    <tr>\n      <th>education-num</th>\n      <td>0.03192</td>\n      <td>0.002161</td>\n      <td>2.507753e-06</td>\n      <td>5</td>\n      <td>0.036371</td>\n      <td>0.027469</td>\n    </tr>\n    <tr>\n      <th>capital-gain</th>\n      <td>0.03052</td>\n      <td>0.002062</td>\n      <td>2.485369e-06</td>\n      <td>5</td>\n      <td>0.034766</td>\n      <td>0.026274</td>\n    </tr>\n    <tr>\n      <th>age</th>\n      <td>0.01280</td>\n      <td>0.003718</td>\n      <td>7.656432e-04</td>\n      <td>5</td>\n      <td>0.020454</td>\n      <td>0.005146</td>\n    </tr>\n    <tr>\n      <th>hours-per-week</th>\n      <td>0.01152</td>\n      <td>0.004582</td>\n      <td>2.460466e-03</td>\n      <td>5</td>\n      <td>0.020954</td>\n      <td>0.002086</td>\n    </tr>\n    <tr>\n      <th>occupation</th>\n      <td>0.00476</td>\n      <td>0.001711</td>\n      <td>1.700352e-03</td>\n      <td>5</td>\n      <td>0.008283</td>\n      <td>0.001237</td>\n    </tr>\n    <tr>\n      <th>relationship</th>\n      <td>0.00344</td>\n      <td>0.000167</td>\n      <td>6.697221e-07</td>\n      <td>5</td>\n      <td>0.003785</td>\n      <td>0.003095</td>\n    </tr>\n    <tr>\n      <th>workclass</th>\n      <td>0.00184</td>\n      <td>0.001596</td>\n      <td>3.074391e-02</td>\n      <td>5</td>\n      <td>0.005127</td>\n      <td>-0.001447</td>\n    </tr>\n    <tr>\n      <th>native-country</th>\n      <td>0.00112</td>\n      <td>0.000795</td>\n      <td>1.725293e-02</td>\n      <td>5</td>\n      <td>0.002757</td>\n      <td>-0.000517</td>\n    </tr>\n    <tr>\n      <th>sex</th>\n      <td>0.00112</td>\n      <td>0.000303</td>\n      <td>5.869020e-04</td>\n      <td>5</td>\n      <td>0.001745</td>\n      <td>0.000495</td>\n    </tr>\n    <tr>\n      <th>education</th>\n      <td>0.00040</td>\n      <td>0.001030</td>\n      <td>2.170027e-01</td>\n      <td>5</td>\n      <td>0.002520</td>\n      <td>-0.001720</td>\n    </tr>\n    <tr>\n      <th>capital-loss</th>\n      <td>0.00024</td>\n      <td>0.000555</td>\n      <td>1.941545e-01</td>\n      <td>5</td>\n      <td>0.001383</td>\n      <td>-0.000903</td>\n    </tr>\n    <tr>\n      <th>race</th>\n      <td>-0.00052</td>\n      <td>0.000807</td>\n      <td>8.883573e-01</td>\n      <td>5</td>\n      <td>0.001143</td>\n      <td>-0.002183</td>\n    </tr>\n    <tr>\n      <th>fnlwgt</th>\n      <td>-0.00156</td>\n      <td>0.002161</td>\n      <td>9.091426e-01</td>\n      <td>5</td>\n      <td>0.002889</td>\n      <td>-0.006009</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:38:13.282854Z",
     "start_time": "2023-12-27T06:38:08.233031Z"
    }
   },
   "id": "567ebed45b3ba83c"
  },
  {
   "cell_type": "markdown",
   "id": "ef4f97a2",
   "metadata": {},
   "source": [
    "The `importance` column is an estimate for the amount the evaluation metric score would drop if the feature were removed from the data.\n",
    "Negative values of `importance` mean that it is likely to improve the results if re-fit with the feature removed.\n",
    "\n",
    "When we call `predict()`, AutoGluon automatically predicts with the model that displayed the best performance on validation data (i.e. the weighted-ensemble)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "'WeightedEnsemble_L2'"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.model_best"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:38:29.000063Z",
     "start_time": "2023-12-27T06:38:28.717535Z"
    }
   },
   "id": "79066cd8f9a34ee8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can instead specify which model to use for predictions like this:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb0ca088eaf1e452"
  },
  {
   "cell_type": "markdown",
   "id": "90aab2e2",
   "metadata": {},
   "source": [
    "```\n",
    "predictor.predict(test_data, model='LightGBM')\n",
    "```\n",
    "\n",
    "You can get the list of trained models via `.leaderboard()` or `.model_names()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "['KNeighborsUnif',\n 'KNeighborsDist',\n 'LightGBMXT',\n 'LightGBM',\n 'RandomForestGini',\n 'RandomForestEntr',\n 'CatBoost',\n 'ExtraTreesGini',\n 'ExtraTreesEntr',\n 'NeuralNetFastAI',\n 'XGBoost',\n 'NeuralNetTorch',\n 'LightGBMLarge',\n 'WeightedEnsemble_L2']"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.model_names()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:39:37.874725Z",
     "start_time": "2023-12-27T06:39:37.694658Z"
    }
   },
   "id": "6eaa4acf8afdf20a"
  },
  {
   "cell_type": "markdown",
   "id": "d0a30ee6",
   "metadata": {},
   "source": [
    "The scores of predictive performance above were based on a default evaluation metric (accuracy for binary classification). Performance in certain applications may be measured by different metrics than the ones AutoGluon optimizes for by default. If you know the metric that counts in your application, you should specify it via the `eval_metric` argument as demonstrated in the next section.\n",
    "\n",
    "## Presets\n",
    "\n",
    "AutoGluon comes with a variety of presets that can be specified in the call to `.fit` via the `presets` argument. `medium_quality` is used by default to encourage initial prototyping, but for serious usage, the other presets should be used instead.\n",
    "\n",
    "| Preset         | Model Quality                                          | Use Cases                                                                                                                                               | Fit Time (Ideal) | Inference Time (Relative to medium_quality) | Disk Usage |\n",
    "| :------------- |:-------------------------------------------------------| :------------------------------------------------------------------------------------------------------------------------------------------------------ |:-----------------| :------------------------------------------ | :--------- |\n",
    "| best_quality   | State-of-the-art (SOTA), much better than high_quality | When accuracy is what matters                                                                                                                           | 16x+             | 32x+                                        | 16x+       |\n",
    "| high_quality   | Better than good_quality                               | When a very powerful, portable solution with fast inference is required: Large-scale batch inference                                                    | 16x+             | 4x                                          | 2x         |\n",
    "| good_quality   | Stronger than any other AutoML Framework               | When a powerful, highly portable solution with very fast inference is required: Billion-scale batch inference, sub-100ms online-inference, edge-devices | 16x              | 2x                                          | 0.1x       |\n",
    "| medium_quality | Competitive with other top AutoML Frameworks           | Initial prototyping, establishing a performance baseline                                                                                                | 1x               | 1x                                          | 1x         |\n",
    "\n",
    "We recommend users to start with `medium_quality` to get a sense of the problem and identify any data related issues. If `medium_quality` is taking too long to train, consider subsampling the training data during this prototyping phase.  \n",
    "Once you are comfortable, next try `best_quality`. Make sure to specify at least 16x the `time_limit` value as used in `medium_quality`. Once finished, you should have a very powerful solution that is often stronger than `medium_quality`.  \n",
    "Make sure to consider holding out test data that AutoGluon never sees during training to ensure that the models are performing as expected in terms of performance.  \n",
    "Once you evaluate both `best_quality` and `medium_quality`, check if either satisfies your needs. If neither do, consider trying `high_quality` and/or `good_quality`.  \n",
    "If none of the presets satisfy requirements, refer to [Predicting Columns in a Table - In Depth](tabular-indepth.ipynb) for more advanced AutoGluon options.\n",
    "\n",
    "## Maximizing predictive performance\n",
    "\n",
    "**Note:** You should not call `fit()` with entirely default arguments if you are benchmarking AutoGluon-Tabular or hoping to maximize its accuracy!\n",
    "To get the best predictive accuracy with AutoGluon, you should generally use it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "358b121a",
   "metadata": {
    "tags": [
     "hide-output"
    ],
    "ExecuteTime": {
     "end_time": "2023-12-27T06:41:07.088948Z",
     "start_time": "2023-12-27T06:40:05.921752Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231227_064005\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 60 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: AutogluonModels/ag-20231227_064005/ds_sub_fit/sub_fit_ho.\n",
      "2023-12-27 15:40:07,503\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n",
      "Spend 39 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 21 seconds.\n",
      "Starting full fit now with num_stack_levels 1.\n",
      "Beginning AutoGluon training ... Time limit = 21s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231227_064005\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 23.2.0: Wed Nov 15 21:54:10 PST 2023; root:xnu-10002.61.3~2/RELEASE_X86_64\n",
      "CPU Count:          16\n",
      "Memory Avail:       46.19 GB / 64.00 GB (72.2%)\n",
      "Disk Space Avail:   454.87 GB / 931.55 GB (48.8%)\n",
      "===================================================\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column:       class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    47294.68 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.2s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 13.84s of the 20.75s of remaining time.\n",
      "\t0.5196\t = Validation score   (roc_auc)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 13.77s of the 20.67s of remaining time.\n",
      "\t0.537\t = Validation score   (roc_auc)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 13.72s of the 20.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.01%)\n",
      "\t0.8912\t = Validation score   (roc_auc)\n",
      "\t7.12s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 20.78s of the -0.05s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.8912\t = Validation score   (roc_auc)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 20.78s of the -0.58s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.8912\t = Validation score   (roc_auc)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 21.78s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231227_064005\")\n"
     ]
    }
   ],
   "source": [
    "time_limit = 60  # for quick demonstration only, you should set this to longest time you are willing to wait (in seconds)\n",
    "metric = 'roc_auc'  # specify your evaluation metric here\n",
    "predictor = TabularPredictor(label, eval_metric=metric).fit(train_data, time_limit=time_limit, presets='best_quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "                   model  score_test  score_val eval_metric  pred_time_test  \\\n0      LightGBMXT_BAG_L1    0.900085   0.891223     roc_auc        0.276320   \n1    WeightedEnsemble_L3    0.900085   0.891223     roc_auc        0.278716   \n2    WeightedEnsemble_L2    0.900085   0.891223     roc_auc        0.279088   \n3  KNeighborsDist_BAG_L1    0.525998   0.536956     roc_auc        0.034281   \n4  KNeighborsUnif_BAG_L1    0.514970   0.519604     roc_auc        0.031536   \n\n   pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n0       0.059960  7.115701                 0.276320                0.059960   \n1       0.060577  7.286543                 0.002396                0.000617   \n2       0.060605  7.298553                 0.002768                0.000645   \n3       0.020751  0.008583                 0.034281                0.020751   \n4       0.040377  0.009176                 0.031536                0.040377   \n\n   fit_time_marginal  stack_level  can_infer  fit_order  \n0           7.115701            1       True          3  \n1           0.170842            3       True          5  \n2           0.182852            2       True          4  \n3           0.008583            1       True          2  \n4           0.009176            1       True          1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LightGBMXT_BAG_L1</td>\n      <td>0.900085</td>\n      <td>0.891223</td>\n      <td>roc_auc</td>\n      <td>0.276320</td>\n      <td>0.059960</td>\n      <td>7.115701</td>\n      <td>0.276320</td>\n      <td>0.059960</td>\n      <td>7.115701</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WeightedEnsemble_L3</td>\n      <td>0.900085</td>\n      <td>0.891223</td>\n      <td>roc_auc</td>\n      <td>0.278716</td>\n      <td>0.060577</td>\n      <td>7.286543</td>\n      <td>0.002396</td>\n      <td>0.000617</td>\n      <td>0.170842</td>\n      <td>3</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>0.900085</td>\n      <td>0.891223</td>\n      <td>roc_auc</td>\n      <td>0.279088</td>\n      <td>0.060605</td>\n      <td>7.298553</td>\n      <td>0.002768</td>\n      <td>0.000645</td>\n      <td>0.182852</td>\n      <td>2</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>KNeighborsDist_BAG_L1</td>\n      <td>0.525998</td>\n      <td>0.536956</td>\n      <td>roc_auc</td>\n      <td>0.034281</td>\n      <td>0.020751</td>\n      <td>0.008583</td>\n      <td>0.034281</td>\n      <td>0.020751</td>\n      <td>0.008583</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>KNeighborsUnif_BAG_L1</td>\n      <td>0.514970</td>\n      <td>0.519604</td>\n      <td>roc_auc</td>\n      <td>0.031536</td>\n      <td>0.040377</td>\n      <td>0.009176</td>\n      <td>0.031536</td>\n      <td>0.040377</td>\n      <td>0.009176</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:41:07.526322Z",
     "start_time": "2023-12-27T06:41:07.063122Z"
    }
   },
   "id": "b45474df26853911"
  },
  {
   "cell_type": "markdown",
   "id": "cf8a57a7",
   "metadata": {},
   "source": [
    "This command implements the following strategy to maximize accuracy:\n",
    "\n",
    "- Specify the argument `presets='best_quality'`, which allows AutoGluon to automatically construct powerful model ensembles based on [stacking/bagging](https://arxiv.org/abs/2003.06505), and will greatly improve the resulting predictions if granted sufficient training time. The default value of `presets` is `'medium_quality'`, which produces _less_ accurate models but facilitates faster prototyping. With `presets`, you can flexibly prioritize predictive accuracy vs. training/inference speed. For example, if you care less about predictive performance and want to quickly deploy a basic model, consider using: `presets=['good_quality', 'optimize_for_deployment']`.\n",
    "\n",
    "- Provide the parameter `eval_metric` to `TabularPredictor()` if you know what metric will be used to evaluate predictions in your application. Some other non-default metrics you might use include things like: `'f1'` (for binary classification), `'roc_auc'` (for binary classification), `'log_loss'` (for classification), `'mean_absolute_error'` (for regression), `'median_absolute_error'` (for regression). You can also define your own custom metric function. For more information refer to [Adding a custom metric to AutoGluon](advanced/tabular-custom-metric.ipynb).\n",
    "\n",
    "- Include all your data in `train_data` and do not provide `tuning_data` (AutoGluon will split the data more intelligently to fit its needs).\n",
    "\n",
    "- Do not specify the `hyperparameter_tune_kwargs` argument (counterintuitively, hyperparameter tuning is not the best way to spend a limited training time budgets, as model ensembling is often superior). We recommend you only use `hyperparameter_tune_kwargs` if your goal is to deploy a single model rather than an ensemble.\n",
    "\n",
    "- Do not specify the `hyperparameters` argument (allow AutoGluon to adaptively select which models/hyperparameters to use).\n",
    "\n",
    "- Set `time_limit` to the longest amount of time (in seconds) that you are willing to wait. AutoGluon's predictive performance improves the longer `fit()` is allowed to run.\n",
    "\n",
    "## Regression (predicting numeric table columns):\n",
    "\n",
    "To demonstrate that `fit()` can also automatically handle regression tasks, we now try to predict the numeric `age` variable in the same table based on the other features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce850e3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T06:41:07.527065Z",
     "start_time": "2023-12-27T06:41:07.478059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "6118     51\n23204    58\n29590    40\n18116    37\n33964    62\nName: age, dtype: int64"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_column = 'age'\n",
    "train_data[age_column].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba6bfd5",
   "metadata": {},
   "source": [
    "We again call `fit()`, imposing a time-limit this time (in seconds), and also demonstrate a shorthand method to evaluate the resulting model on the test data (which contain labels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36e8f913",
   "metadata": {
    "tags": [
     "hide-output"
    ],
    "ExecuteTime": {
     "end_time": "2023-12-27T06:41:15.400897Z",
     "start_time": "2023-12-27T06:41:07.492419Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"agModels-predictAge\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 23.2.0: Wed Nov 15 21:54:10 PST 2023; root:xnu-10002.61.3~2/RELEASE_X86_64\n",
      "CPU Count:          16\n",
      "Memory Avail:       48.09 GB / 64.00 GB (75.1%)\n",
      "Disk Space Avail:   454.86 GB / 931.55 GB (48.8%)\n",
      "===================================================\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column:       age\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (85, 17, 39.652, 13.52393)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    49245.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.31 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 5 | ['fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "\t\t('object', []) : 9 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 5 | ['fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t0.2s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 59.82s of the 59.82s of remaining time.\n",
      "\t-15.6869\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 59.78s of the 59.78s of remaining time.\n",
      "\t-15.1801\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 59.75s of the 59.75s of remaining time.\n",
      "\t-11.7092\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 59.29s of the 59.29s of remaining time.\n",
      "\t-11.9295\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 58.88s of the 58.88s of remaining time.\n",
      "\t-11.6669\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 57.99s of the 57.99s of remaining time.\n",
      "\t-11.7993\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.92s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 57.06s of the 57.06s of remaining time.\n",
      "\t-11.3702\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 56.31s of the 56.31s of remaining time.\n",
      "\t-12.0733\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.82s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 55.46s of the 55.46s of remaining time.\n",
      "\t-12.2892\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 55.08s of the 55.08s of remaining time.\n",
      "\t-11.9446\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.87s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 53.19s of the 53.18s of remaining time.\n",
      "\t-12.3153\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.82s of the 52.57s of remaining time.\n",
      "\tEnsemble Weights: {'ExtraTreesMSE': 0.577, 'NeuralNetTorch': 0.154, 'XGBoost': 0.115, 'LightGBMXT': 0.096, 'KNeighborsDist': 0.038, 'NeuralNetFastAI': 0.019}\n",
      "\t-11.2341\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 7.84s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictAge\")\n"
     ]
    }
   ],
   "source": [
    "predictor_age = TabularPredictor(label=age_column, path=\"agModels-predictAge\").fit(train_data, time_limit=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "{'root_mean_squared_error': -10.484248330242233,\n 'mean_squared_error': -109.91946305018706,\n 'mean_absolute_error': -8.21703138965486,\n 'r2': 0.4124591324567525,\n 'pearsonr': 0.6432746192485945,\n 'median_absolute_error': -6.826347351074219}"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_age.evaluate(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T06:41:16.034058Z",
     "start_time": "2023-12-27T06:41:15.358806Z"
    }
   },
   "id": "d4564a06d1766c76"
  },
  {
   "cell_type": "markdown",
   "id": "46af4e18",
   "metadata": {},
   "source": [
    "Note that we didn't need to tell AutoGluon this is a regression problem, it automatically inferred this from the data and reported the appropriate performance metric (RMSE by default). To specify a particular evaluation metric other than the default, set the `eval_metric` parameter of [TabularPredictor()](../../api/autogluon.tabular.TabularPredictor.rst) and AutoGluon will tailor its models to optimize your metric (e.g. `eval_metric = 'mean_absolute_error'`). For evaluation metrics where higher values are worse (like RMSE), AutoGluon will flip their sign and print them as negative values during training (as it internally assumes higher values are better). You can even specify a custom metric by following the [Custom Metric Tutorial](advanced/tabular-custom-metric.ipynb).\n",
    "\n",
    "We can call leaderboard to see the per-model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a20746a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T06:41:16.855337Z",
     "start_time": "2023-12-27T06:41:15.939373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                  model  score_test  score_val              eval_metric  \\\n0   WeightedEnsemble_L2  -10.484248 -11.234127  root_mean_squared_error   \n1         ExtraTreesMSE  -10.655664 -11.370194  root_mean_squared_error   \n2       RandomForestMSE  -10.745757 -11.666917  root_mean_squared_error   \n3              CatBoost  -10.780312 -11.799279  root_mean_squared_error   \n4            LightGBMXT  -10.837373 -11.709228  root_mean_squared_error   \n5              LightGBM  -10.972156 -11.929546  root_mean_squared_error   \n6        NeuralNetTorch  -11.098373 -11.944570  root_mean_squared_error   \n7               XGBoost  -11.115033 -12.289224  root_mean_squared_error   \n8       NeuralNetFastAI  -11.225699 -12.073282  root_mean_squared_error   \n9         LightGBMLarge  -11.469922 -12.315314  root_mean_squared_error   \n10       KNeighborsUnif  -14.902058 -15.686937  root_mean_squared_error   \n11       KNeighborsDist  -15.771259 -15.180149  root_mean_squared_error   \n\n    pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  \\\n0         0.587843       0.128787  4.497615                 0.006487   \n1         0.176139       0.066450  0.625381                 0.176139   \n2         0.145814       0.090702  0.726872                 0.145814   \n3         0.018356       0.006132  0.922184                 0.018356   \n4         0.061981       0.007783  0.438341                 0.061981   \n5         0.020171       0.006482  0.395815                 0.020171   \n6         0.075944       0.013845  1.865778                 0.075944   \n7         0.044458       0.009845  0.357898                 0.044458   \n8         0.190200       0.014033  0.824436                 0.190200   \n9         0.037370       0.005458  0.584452                 0.037370   \n10        0.031215       0.019558  0.012018                 0.031215   \n11        0.032634       0.016367  0.008226                 0.032634   \n\n    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n0                 0.000464           0.377555            2       True   \n1                 0.066450           0.625381            1       True   \n2                 0.090702           0.726872            1       True   \n3                 0.006132           0.922184            1       True   \n4                 0.007783           0.438341            1       True   \n5                 0.006482           0.395815            1       True   \n6                 0.013845           1.865778            1       True   \n7                 0.009845           0.357898            1       True   \n8                 0.014033           0.824436            1       True   \n9                 0.005458           0.584452            1       True   \n10                0.019558           0.012018            1       True   \n11                0.016367           0.008226            1       True   \n\n    fit_order  \n0          12  \n1           7  \n2           5  \n3           6  \n4           3  \n5           4  \n6          10  \n7           9  \n8           8  \n9          11  \n10          1  \n11          2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>-10.484248</td>\n      <td>-11.234127</td>\n      <td>root_mean_squared_error</td>\n      <td>0.587843</td>\n      <td>0.128787</td>\n      <td>4.497615</td>\n      <td>0.006487</td>\n      <td>0.000464</td>\n      <td>0.377555</td>\n      <td>2</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ExtraTreesMSE</td>\n      <td>-10.655664</td>\n      <td>-11.370194</td>\n      <td>root_mean_squared_error</td>\n      <td>0.176139</td>\n      <td>0.066450</td>\n      <td>0.625381</td>\n      <td>0.176139</td>\n      <td>0.066450</td>\n      <td>0.625381</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForestMSE</td>\n      <td>-10.745757</td>\n      <td>-11.666917</td>\n      <td>root_mean_squared_error</td>\n      <td>0.145814</td>\n      <td>0.090702</td>\n      <td>0.726872</td>\n      <td>0.145814</td>\n      <td>0.090702</td>\n      <td>0.726872</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CatBoost</td>\n      <td>-10.780312</td>\n      <td>-11.799279</td>\n      <td>root_mean_squared_error</td>\n      <td>0.018356</td>\n      <td>0.006132</td>\n      <td>0.922184</td>\n      <td>0.018356</td>\n      <td>0.006132</td>\n      <td>0.922184</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LightGBMXT</td>\n      <td>-10.837373</td>\n      <td>-11.709228</td>\n      <td>root_mean_squared_error</td>\n      <td>0.061981</td>\n      <td>0.007783</td>\n      <td>0.438341</td>\n      <td>0.061981</td>\n      <td>0.007783</td>\n      <td>0.438341</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LightGBM</td>\n      <td>-10.972156</td>\n      <td>-11.929546</td>\n      <td>root_mean_squared_error</td>\n      <td>0.020171</td>\n      <td>0.006482</td>\n      <td>0.395815</td>\n      <td>0.020171</td>\n      <td>0.006482</td>\n      <td>0.395815</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NeuralNetTorch</td>\n      <td>-11.098373</td>\n      <td>-11.944570</td>\n      <td>root_mean_squared_error</td>\n      <td>0.075944</td>\n      <td>0.013845</td>\n      <td>1.865778</td>\n      <td>0.075944</td>\n      <td>0.013845</td>\n      <td>1.865778</td>\n      <td>1</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>XGBoost</td>\n      <td>-11.115033</td>\n      <td>-12.289224</td>\n      <td>root_mean_squared_error</td>\n      <td>0.044458</td>\n      <td>0.009845</td>\n      <td>0.357898</td>\n      <td>0.044458</td>\n      <td>0.009845</td>\n      <td>0.357898</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>NeuralNetFastAI</td>\n      <td>-11.225699</td>\n      <td>-12.073282</td>\n      <td>root_mean_squared_error</td>\n      <td>0.190200</td>\n      <td>0.014033</td>\n      <td>0.824436</td>\n      <td>0.190200</td>\n      <td>0.014033</td>\n      <td>0.824436</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>LightGBMLarge</td>\n      <td>-11.469922</td>\n      <td>-12.315314</td>\n      <td>root_mean_squared_error</td>\n      <td>0.037370</td>\n      <td>0.005458</td>\n      <td>0.584452</td>\n      <td>0.037370</td>\n      <td>0.005458</td>\n      <td>0.584452</td>\n      <td>1</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>KNeighborsUnif</td>\n      <td>-14.902058</td>\n      <td>-15.686937</td>\n      <td>root_mean_squared_error</td>\n      <td>0.031215</td>\n      <td>0.019558</td>\n      <td>0.012018</td>\n      <td>0.031215</td>\n      <td>0.019558</td>\n      <td>0.012018</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>KNeighborsDist</td>\n      <td>-15.771259</td>\n      <td>-15.180149</td>\n      <td>root_mean_squared_error</td>\n      <td>0.032634</td>\n      <td>0.016367</td>\n      <td>0.008226</td>\n      <td>0.032634</td>\n      <td>0.016367</td>\n      <td>0.008226</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_age.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d692ceb",
   "metadata": {},
   "source": [
    "**Data Formats:** AutoGluon can currently operate on data tables already loaded into Python as pandas DataFrames, or those stored in files of [CSV format](https://en.wikipedia.org/wiki/Comma-separated_values) or [Parquet format](https://databricks.com/glossary/what-is-parquet). If your data lives in multiple tables, you will first need to join them into a single table whose rows correspond to statistically independent observations (datapoints) and columns correspond to different features (aka. variables/covariates).\n",
    "\n",
    "Refer to the [TabularPredictor documentation](../../api/autogluon.tabular.TabularPredictor.rst) to see all of the available methods/options.\n",
    "\n",
    "## Advanced Usage\n",
    "\n",
    "For more advanced usage examples of AutoGluon, refer to the [In Depth Tutorial](tabular-indepth.ipynb)\n",
    "\n",
    "If you are interested in deployment optimization, refer to the [Deployment Optimization Tutorial](advanced/tabular-deployment.ipynb).\n",
    "\n",
    "For adding custom models to AutoGluon, refer to the [Custom Model](advanced/tabular-custom-model.ipynb) and [Custom Model Advanced](advanced/tabular-custom-model-advanced.ipynb) tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8009dec51f6ca871"
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "venv_ag_310",
   "language": "python",
   "display_name": "venv_ag_310"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
