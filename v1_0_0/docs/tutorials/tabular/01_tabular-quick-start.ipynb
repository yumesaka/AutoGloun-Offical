{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGluon Tabular - Quick Start\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/autogluon/autogluon/blob/master/docs/tutorials/tabular/tabular-quick-start.ipynb)\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/autogluon/autogluon/blob/master/docs/tutorials/tabular/tabular-quick-start.ipynb)\n",
    "\n",
    "In this tutorial, we will see how to use AutoGluon's `TabularPredictor` to predict the values of a target column based on the other columns in a tabular dataset.\n",
    "\n",
    "Begin by making sure AutoGluon is installed, and then import AutoGluon's `TabularDataset` and `TabularPredictor`. We will use the former to load data and the latter to train models and make predictions. "
   ],
   "id": "688ad0938f1752be"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-output"
    ],
    "ExecuteTime": {
     "end_time": "2023-12-26T10:17:27.818722Z",
     "start_time": "2023-12-26T10:17:27.809794Z"
    }
   },
   "outputs": [],
   "source": [
    "# !python -m pip install --upgrade pip\n",
    "# !python -m pip install autogluon"
   ],
   "id": "3804b5c7d11a9891"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T06:21:46.647689Z",
     "start_time": "2023-12-27T06:21:41.424465Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elnath/anaconda3/envs/venv_ag_310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ],
   "id": "6be8fb99702bf01e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Data"
   ],
   "id": "6bfd71b3b65eb529"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial we will use a dataset from the cover story of [Nature issue 7887](https://www.nature.com/nature/volumes/600/issues/7887): [AI-guided intuition for math theorems](https://www.nature.com/articles/s41586-021-04086-x.pdf). The goal is to predict a knot's signature based on its properties. We sampled 10K training and 5K test examples from the [original data](https://github.com/deepmind/mathematics_conjectures/blob/main/knot_theory.ipynb). The sampled dataset make this tutorial run quickly, but AutoGluon can handle the full dataset if desired.\n",
    "\n",
    "We load this dataset directly from a URL. AutoGluon's `TabularDataset` is a subclass of pandas [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html), so any `DataFrame` methods can be used on `TabularDataset` as well."
   ],
   "id": "c8222fcc3487344c"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T06:22:36.252041Z",
     "start_time": "2023-12-27T06:22:35.455748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0  chern_simons  cusp_volume  hyperbolic_adjoint_torsion_degree  \\\n0       70746      0.090530    12.226322                                  0   \n1      240827      0.232453    13.800773                                  0   \n2      155659     -0.144099    14.761030                                  0   \n3      239963     -0.171668    13.738019                                  0   \n4       90504      0.235188    15.896359                                  0   \n\n   hyperbolic_torsion_degree  injectivity_radius  longitudinal_translation  \\\n0                         10            0.507756                 10.685555   \n1                         14            0.413645                 10.453156   \n2                         14            0.436928                 13.405199   \n3                         22            0.249481                 27.819496   \n4                         10            0.389329                 15.330971   \n\n   meridinal_translation_imag  meridinal_translation_real  \\\n0                    1.144192                   -0.519157   \n1                    1.320249                   -0.158522   \n2                    1.101142                    0.768894   \n3                    0.493827                   -1.188718   \n4                    1.036879                    0.722828   \n\n   short_geodesic_imag_part  short_geodesic_real_part  Symmetry_0  \\\n0                 -2.760601                  1.015512         0.0   \n1                 -3.013258                  0.827289         0.0   \n2                  2.233106                  0.873856         0.0   \n3                 -2.042771                  0.498961         0.0   \n4                 -3.056138                  0.778658         0.0   \n\n   Symmetry_D3  Symmetry_D4  Symmetry_D6  Symmetry_D8  Symmetry_Z/2 + Z/2  \\\n0          0.0          0.0          0.0          0.0                 1.0   \n1          0.0          0.0          0.0          0.0                 1.0   \n2          0.0          0.0          0.0          0.0                 0.0   \n3          0.0          0.0          0.0          0.0                 0.0   \n4          0.0          0.0          0.0          0.0                 0.0   \n\n      volume  signature  \n0  11.393225         -2  \n1  12.742782          0  \n2  15.236505          2  \n3  17.279890         -8  \n4  16.749298          4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>chern_simons</th>\n      <th>cusp_volume</th>\n      <th>hyperbolic_adjoint_torsion_degree</th>\n      <th>hyperbolic_torsion_degree</th>\n      <th>injectivity_radius</th>\n      <th>longitudinal_translation</th>\n      <th>meridinal_translation_imag</th>\n      <th>meridinal_translation_real</th>\n      <th>short_geodesic_imag_part</th>\n      <th>short_geodesic_real_part</th>\n      <th>Symmetry_0</th>\n      <th>Symmetry_D3</th>\n      <th>Symmetry_D4</th>\n      <th>Symmetry_D6</th>\n      <th>Symmetry_D8</th>\n      <th>Symmetry_Z/2 + Z/2</th>\n      <th>volume</th>\n      <th>signature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>70746</td>\n      <td>0.090530</td>\n      <td>12.226322</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.507756</td>\n      <td>10.685555</td>\n      <td>1.144192</td>\n      <td>-0.519157</td>\n      <td>-2.760601</td>\n      <td>1.015512</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>11.393225</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>240827</td>\n      <td>0.232453</td>\n      <td>13.800773</td>\n      <td>0</td>\n      <td>14</td>\n      <td>0.413645</td>\n      <td>10.453156</td>\n      <td>1.320249</td>\n      <td>-0.158522</td>\n      <td>-3.013258</td>\n      <td>0.827289</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>12.742782</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>155659</td>\n      <td>-0.144099</td>\n      <td>14.761030</td>\n      <td>0</td>\n      <td>14</td>\n      <td>0.436928</td>\n      <td>13.405199</td>\n      <td>1.101142</td>\n      <td>0.768894</td>\n      <td>2.233106</td>\n      <td>0.873856</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>15.236505</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>239963</td>\n      <td>-0.171668</td>\n      <td>13.738019</td>\n      <td>0</td>\n      <td>22</td>\n      <td>0.249481</td>\n      <td>27.819496</td>\n      <td>0.493827</td>\n      <td>-1.188718</td>\n      <td>-2.042771</td>\n      <td>0.498961</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>17.279890</td>\n      <td>-8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>90504</td>\n      <td>0.235188</td>\n      <td>15.896359</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.389329</td>\n      <td>15.330971</td>\n      <td>1.036879</td>\n      <td>0.722828</td>\n      <td>-3.056138</td>\n      <td>0.778658</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>16.749298</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = 'https://raw.githubusercontent.com/mli/ag-docs/main/knot_theory/'\n",
    "train_data = TabularDataset(f'{data_url}train.csv')\n",
    "train_data.head()"
   ],
   "id": "5ec75ca26e70a2b9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our targets are stored in the \"signature\" column, which has 18 unique integers. Even though pandas didn't correctly recognize this data type as categorical, AutoGluon will fix this issue.\n"
   ],
   "id": "f473c60134d9d320"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T06:22:36.265750Z",
     "start_time": "2023-12-27T06:22:36.246875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    10000.000000\nmean        -0.022000\nstd          3.025166\nmin        -12.000000\n25%         -2.000000\n50%          0.000000\n75%          2.000000\nmax         12.000000\nName: signature, dtype: float64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = 'signature'\n",
    "train_data[label].describe()"
   ],
   "id": "a3be45e1d1ad99bf"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We now construct a `TabularPredictor` by specifying the label column name and then train on the dataset with `TabularPredictor.fit()`. We don't need to specify any other parameters. AutoGluon will recognize this is a multi-class classification task, perform automatic feature engineering, train multiple models, and then ensemble the models to create the final predictor. "
   ],
   "id": "c514291f69f019ac"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "hide-output"
    ],
    "ExecuteTime": {
     "end_time": "2023-12-27T07:25:55.483306Z",
     "start_time": "2023-12-27T06:25:46.412455Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231227_062546\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 3600 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: AutogluonModels/ag-20231227_062546/ds_sub_fit/sub_fit_ho.\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n",
      "Spend 946 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 2654 seconds.\n",
      "Starting full fit now with num_stack_levels 1.\n",
      "Beginning AutoGluon training ... Time limit = 2654s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231227_062546\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 23.2.0: Wed Nov 15 21:54:10 PST 2023; root:xnu-10002.61.3~2/RELEASE_X86_64\n",
      "CPU Count:          16\n",
      "Memory Avail:       48.10 GB / 64.00 GB (75.2%)\n",
      "Disk Space Avail:   456.35 GB / 931.55 GB (49.0%)\n",
      "===================================================\n",
      "Train Data Rows:    10000\n",
      "Train Data Columns: 18\n",
      "Label Column:       signature\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 9 out of 13 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9984\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    49252.56 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.37 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['Symmetry_D8']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['chern_simons', 'cusp_volume', 'injectivity_radius', 'longitudinal_translation', 'meridinal_translation_imag', ...]\n",
      "\t\t('int', [])   :  3 | ['Unnamed: 0', 'hyperbolic_adjoint_torsion_degree', 'hyperbolic_torsion_degree']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 9 | ['chern_simons', 'cusp_volume', 'injectivity_radius', 'longitudinal_translation', 'meridinal_translation_imag', ...]\n",
      "\t\t('int', [])       : 3 | ['Unnamed: 0', 'hyperbolic_adjoint_torsion_degree', 'hyperbolic_torsion_degree']\n",
      "\t\t('int', ['bool']) : 5 | ['Symmetry_0', 'Symmetry_D3', 'Symmetry_D4', 'Symmetry_D6', 'Symmetry_Z/2 + Z/2']\n",
      "\t0.1s = Fit runtime\n",
      "\t17 features in original data used to generate 17 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.96 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1768.82s of the 2653.88s of remaining time.\n",
      "\t0.2085\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1768.74s of the 2653.8s of remaining time.\n",
      "\t0.2195\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1768.66s of the 2653.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t0.9445\t = Validation score   (accuracy)\n",
      "\t18.77s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1746.23s of the 2631.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t0.9406\t = Validation score   (accuracy)\n",
      "\t16.82s\t = Training   runtime\n",
      "\t3.23s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1723.48s of the 2608.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t0.9487\t = Validation score   (accuracy)\n",
      "\t8.66s\t = Training   runtime\n",
      "\t0.77s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1710.58s of the 2595.64s of remaining time.\n",
      "\t0.9391\t = Validation score   (accuracy)\n",
      "\t1.43s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1708.36s of the 2593.42s of remaining time.\n",
      "\t0.9427\t = Validation score   (accuracy)\n",
      "\t1.59s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1705.97s of the 2591.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
      "\t0.942\t = Validation score   (accuracy)\n",
      "\t81.89s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1620.47s of the 2505.53s of remaining time.\n",
      "\t0.9391\t = Validation score   (accuracy)\n",
      "\t0.98s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1618.71s of the 2503.77s of remaining time.\n",
      "\t0.9388\t = Validation score   (accuracy)\n",
      "\t0.94s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1616.95s of the 2502.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
      "\t0.9462\t = Validation score   (accuracy)\n",
      "\t14.74s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1598.74s of the 2483.8s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.01%)\n",
      "\t0.936\t = Validation score   (accuracy)\n",
      "\t82.01s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1512.76s of the 2397.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.04%)\n",
      "\t0.9452\t = Validation score   (accuracy)\n",
      "\t20.23s\t = Training   runtime\n",
      "\t1.95s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1486.79s of the 2371.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
      "\t0.943\t = Validation score   (accuracy)\n",
      "\t60.62s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1421.29s of the 2306.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.01%)\n",
      "\t0.9441\t = Validation score   (accuracy)\n",
      "\t74.18s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 1343.77s of the 2228.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
      "\t0.9475\t = Validation score   (accuracy)\n",
      "\t26.7s\t = Training   runtime\n",
      "\t4.74s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 1310.83s of the 2195.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t0.9498\t = Validation score   (accuracy)\n",
      "\t61.15s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 1245.5s of the 2130.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.07%)\n",
      "\t0.9429\t = Validation score   (accuracy)\n",
      "\t193.08s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 1046.33s of the 1931.4s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t0.9358\t = Validation score   (accuracy)\n",
      "\t55.83s\t = Training   runtime\n",
      "\t21.55s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 980.4s of the 1865.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.01%)\n",
      "\t0.9447\t = Validation score   (accuracy)\n",
      "\t93.35s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 883.88s of the 1768.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.12%)\n",
      "\t0.9438\t = Validation score   (accuracy)\n",
      "\t40.66s\t = Training   runtime\n",
      "\t4.2s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 838.69s of the 1723.75s of remaining time.\n",
      "\t0.9444\t = Validation score   (accuracy)\n",
      "\t1.55s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 836.25s of the 1721.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t0.9376\t = Validation score   (accuracy)\n",
      "\t104.31s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 727.59s of the 1612.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t0.9359\t = Validation score   (accuracy)\n",
      "\t9.23s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 715.42s of the 1600.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.07%)\n",
      "\t0.9399\t = Validation score   (accuracy)\n",
      "\t468.31s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 242.67s of the 1127.73s of remaining time.\n",
      "\t0.9416\t = Validation score   (accuracy)\n",
      "\t1.86s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 240.25s of the 1125.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.04%)\n",
      "\t0.9338\t = Validation score   (accuracy)\n",
      "\t25.19s\t = Training   runtime\n",
      "\t6.49s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 208.78s of the 1093.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t0.9472\t = Validation score   (accuracy)\n",
      "\t35.58s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 170.26s of the 1055.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.04%)\n",
      "\t0.945\t = Validation score   (accuracy)\n",
      "\t11.53s\t = Training   runtime\n",
      "\t0.77s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 154.26s of the 1039.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.01%)\n",
      "\t0.9354\t = Validation score   (accuracy)\n",
      "\t105.97s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 44.73s of the 929.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.04%)\n",
      "\t0.9471\t = Validation score   (accuracy)\n",
      "\t11.0s\t = Training   runtime\n",
      "\t3.43s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 29.33s of the 914.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.01%)\n",
      "\t0.9298\t = Validation score   (accuracy)\n",
      "\t28.08s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 882.42s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_r79_BAG_L1': 0.31, 'RandomForestEntr_BAG_L1': 0.172, 'NeuralNetTorch_r22_BAG_L1': 0.172, 'ExtraTrees_r42_BAG_L1': 0.138, 'LightGBM_BAG_L1': 0.069, 'NeuralNetTorch_BAG_L1': 0.034, 'LightGBMLarge_BAG_L1': 0.034, 'NeuralNetFastAI_r191_BAG_L1': 0.034, 'NeuralNetFastAI_r145_BAG_L1': 0.034}\n",
      "\t0.9586\t = Validation score   (accuracy)\n",
      "\t7.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 875.3s of the 875.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.27%)\n",
      "\t0.9598\t = Validation score   (accuracy)\n",
      "\t22.72s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 849.37s of the 849.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.34%)\n",
      "\t0.9576\t = Validation score   (accuracy)\n",
      "\t46.57s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 798.36s of the 798.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.32%)\n",
      "\t0.9578\t = Validation score   (accuracy)\n",
      "\t90.26s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 703.86s of the 703.59s of remaining time.\n",
      "\t0.9575\t = Validation score   (accuracy)\n",
      "\t3.36s\t = Training   runtime\n",
      "\t1.71s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 698.37s of the 698.11s of remaining time.\n",
      "\t0.957\t = Validation score   (accuracy)\n",
      "\t2.9s\t = Training   runtime\n",
      "\t1.79s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 693.44s of the 693.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.44%)\n",
      "\t0.9582\t = Validation score   (accuracy)\n",
      "\t550.85s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 139.42s of the 139.15s of remaining time.\n",
      "\t0.9566\t = Validation score   (accuracy)\n",
      "\t1.24s\t = Training   runtime\n",
      "\t1.69s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 136.16s of the 135.89s of remaining time.\n",
      "\t0.9557\t = Validation score   (accuracy)\n",
      "\t1.36s\t = Training   runtime\n",
      "\t1.81s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 132.68s of the 132.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.49%)\n",
      "\t0.9589\t = Validation score   (accuracy)\n",
      "\t94.48s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 34.72s of the 34.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.15%)\n",
      "\t0.9512\t = Validation score   (accuracy)\n",
      "\t26.22s\t = Training   runtime\n",
      "\t2.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -0.84s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.545, 'RandomForestGini_BAG_L2': 0.216, 'NeuralNetFastAI_r191_BAG_L1': 0.068, 'RandomForestEntr_BAG_L2': 0.068, 'XGBoost_BAG_L2': 0.057, 'RandomForestEntr_BAG_L1': 0.034, 'NeuralNetTorch_BAG_L2': 0.011}\n",
      "\t0.9609\t = Validation score   (accuracy)\n",
      "\t7.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2662.2s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231227_062546\")\n"
     ]
    }
   ],
   "source": [
    "# predictor = TabularPredictor(label=label).fit(train_data)\n",
    "predictor = TabularPredictor(label=label).fit(train_data,presets='best_quality')\n",
    "# predictor = TabularPredictor(label=label).fit(train_data,presets='best_quality' ,time_limit= 60*60*3) # 60sec * 60min * 3hours\n"
   ],
   "id": "6100cf7e354377f8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model fitting should take a few minutes or less depending on your CPU. You can make training faster by specifying the `time_limit` argument. For example, `fit(..., time_limit=60)` will stop training after 60 seconds. Higher time limits will generally result in better prediction performance, and excessively low time limits will prevent AutoGluon from training and ensembling a reasonable set of models.\n",
    "\n"
   ],
   "id": "faf153c1b05d927d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "Once we have a predictor that is fit on the training dataset, we can load a separate set of data to use for prediction and evaulation."
   ],
   "id": "4290ac680b47be14"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T07:26:50.772777Z",
     "start_time": "2023-12-27T07:25:55.484468Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://raw.githubusercontent.com/mli/ag-docs/main/knot_theory/test.csv | Columns = 19 / 19 | Rows = 5000 -> 5000\n"
     ]
    },
    {
     "data": {
      "text/plain": "0   -4\n1    0\n2    0\n3    4\n4    2\nName: signature, dtype: int64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TabularDataset(f'{data_url}test.csv')\n",
    "\n",
    "y_pred = predictor.predict(test_data.drop(columns=[label]))\n",
    "y_pred.head()"
   ],
   "id": "84c9a96672acfb47"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We can evaluate the predictor on the test dataset using the `evaluate()` function, which measures how well our predictor performs on data that was not used for fitting the models."
   ],
   "id": "8db04e1bbbeeb9f6"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T07:27:45.892260Z",
     "start_time": "2023-12-27T07:26:50.775766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'accuracy': 0.9548,\n 'balanced_accuracy': 0.7692721534252841,\n 'mcc': 0.9446369438708256}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data, silent=True)"
   ],
   "id": "ec3771820cd60edf"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoGluon's `TabularPredictor` also provides the `leaderboard()` function, which allows us to evaluate the performance of each individual trained model on the test data."
   ],
   "id": "4f0b5327828b7bd1"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T07:28:44.924396Z",
     "start_time": "2023-12-27T07:27:45.888804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                          model  score_test  score_val eval_metric  \\\n0         ExtraTreesEntr_BAG_L2      0.9556   0.955729    accuracy   \n1       RandomForestEntr_BAG_L2      0.9554   0.957031    accuracy   \n2       RandomForestGini_BAG_L2      0.9552   0.957532    accuracy   \n3           WeightedEnsemble_L3      0.9548   0.960938    accuracy   \n4         ExtraTreesGini_BAG_L2      0.9544   0.956631    accuracy   \n5               LightGBM_BAG_L2      0.9544   0.957833    accuracy   \n6               CatBoost_BAG_L2      0.9542   0.958233    accuracy   \n7        NeuralNetFastAI_BAG_L2      0.9540   0.959836    accuracy   \n8             LightGBMXT_BAG_L2      0.9538   0.957632    accuracy   \n9                XGBoost_BAG_L2      0.9536   0.958934    accuracy   \n10          WeightedEnsemble_L2      0.9518   0.958634    accuracy   \n11              LightGBM_BAG_L1      0.9480   0.948718    accuracy   \n12    NeuralNetTorch_r22_BAG_L1      0.9474   0.944712    accuracy   \n13        NeuralNetTorch_BAG_L2      0.9470   0.951222    accuracy   \n14         LightGBM_r130_BAG_L1      0.9468   0.947115    accuracy   \n15         LightGBM_r131_BAG_L1      0.9468   0.947516    accuracy   \n16        ExtraTrees_r42_BAG_L1      0.9464   0.944411    accuracy   \n17         LightGBMLarge_BAG_L1      0.9460   0.945212    accuracy   \n18  NeuralNetFastAI_r191_BAG_L1      0.9454   0.949820    accuracy   \n19           XGBoost_r89_BAG_L1      0.9452   0.945012    accuracy   \n20           XGBoost_r33_BAG_L1      0.9452   0.943810    accuracy   \n21         CatBoost_r177_BAG_L1      0.9442   0.943009    accuracy   \n22               XGBoost_BAG_L1      0.9438   0.946214    accuracy   \n23           CatBoost_r9_BAG_L1      0.9434   0.942909    accuracy   \n24  NeuralNetFastAI_r145_BAG_L1      0.9434   0.947216    accuracy   \n25              CatBoost_BAG_L1      0.9428   0.942007    accuracy   \n26       NeuralNetFastAI_BAG_L1      0.9424   0.944511    accuracy   \n27          CatBoost_r13_BAG_L1      0.9422   0.939904    accuracy   \n28      RandomForestEntr_BAG_L1      0.9414   0.942708    accuracy   \n29    NeuralNetTorch_r79_BAG_L1      0.9414   0.944111    accuracy   \n30     RandomForest_r195_BAG_L1      0.9402   0.941607    accuracy   \n31            LightGBMXT_BAG_L1      0.9396   0.940605    accuracy   \n32         CatBoost_r137_BAG_L1      0.9376   0.937600    accuracy   \n33        ExtraTreesEntr_BAG_L1      0.9370   0.938802    accuracy   \n34      RandomForestGini_BAG_L1      0.9366   0.939103    accuracy   \n35  NeuralNetFastAI_r102_BAG_L1      0.9354   0.935897    accuracy   \n36        ExtraTreesGini_BAG_L1      0.9354   0.939103    accuracy   \n37    NeuralNetTorch_r30_BAG_L1      0.9352   0.935397    accuracy   \n38          LightGBM_r96_BAG_L1      0.9352   0.935797    accuracy   \n39         LightGBM_r188_BAG_L1      0.9332   0.933794    accuracy   \n40        NeuralNetTorch_BAG_L1      0.9328   0.935998    accuracy   \n41    NeuralNetTorch_r86_BAG_L1      0.9320   0.929788    accuracy   \n42        KNeighborsDist_BAG_L1      0.2238   0.219451    accuracy   \n43        KNeighborsUnif_BAG_L1      0.2190   0.208534    accuracy   \n\n    pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  \\\n0        51.280732      54.951336  1657.623791                 0.239503   \n1        51.227826      54.938805  1659.172585                 0.186597   \n2        51.309514      54.854422  1659.632984                 0.268285   \n3        57.052236      59.865204  1813.271291                 0.005906   \n4        51.262278      54.839176  1657.504687                 0.221049   \n5        51.532950      53.425898  1746.529889                 0.491721   \n6        51.230510      53.272024  2207.118226                 0.189281   \n7        51.939987      53.469257  1678.992049                 0.898758   \n8        51.746619      53.704963  1702.840857                 0.705390   \n9        51.974730      53.470906  1750.743656                 0.933501   \n10        6.098422       5.051507   385.386959                 0.007404   \n11        0.957437       0.771602     8.660446                 0.957437   \n12        0.210832       0.167202    93.352953                 0.210832   \n13       54.759190      55.713939  1682.486234                 3.717961   \n14        2.941569       3.428351    11.004182                 2.941569   \n15        4.137506       4.740445    26.699265                 4.137506   \n16        0.344166       0.582430     1.547200                 0.344166   \n17        1.883965       1.949258    20.234462                 1.883965   \n18        0.845418       0.486018    61.145562                 0.845418   \n19        1.372199       0.772316    11.528171                 1.372199   \n20        3.751048       4.204147    40.664564                 3.751048   \n21        0.141376       0.075096    60.623348                 0.141376   \n22        1.351704       0.813335    14.735926                 1.351704   \n23        0.366138       0.167994   193.077350                 0.366138   \n24        1.162542       0.410296    35.582204                 1.162542   \n25        0.139978       0.080627    81.887159                 0.139978   \n26        0.548068       0.204384    18.767445                 0.548068   \n27        0.331450       0.110940   468.307663                 0.331450   \n28        0.226238       0.450151     1.594295                 0.226238   \n29        0.277757       0.111116    74.177878                 0.277757   \n30        0.291170       0.310577     1.858434                 0.291170   \n31        2.863546       3.233672    16.821245                 2.863546   \n32        0.197300       0.084572   104.314416                 0.197300   \n33        0.337598       0.420395     0.935569                 0.337598   \n34        0.319590       0.466232     1.429103                 0.319590   \n35        0.250275       0.110171     9.228248                 0.250275   \n36        0.266671       0.428307     0.980802                 0.266671   \n37        0.265321       0.116740   105.966872                 0.265321   \n38       18.119450      21.551668    55.833047                18.119450   \n39        6.597619       6.489633    25.191653                 6.597619   \n40        0.182663       0.118833    82.006149                 0.182663   \n41        0.310909       0.226510    28.075688                 0.310909   \n42        0.025430       0.033397     0.018247                 0.025430   \n43        0.024295       0.029563     0.018913                 0.024295   \n\n    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n0                 1.805358           1.355332            2       True   \n1                 1.792827           2.904126            2       True   \n2                 1.708444           3.364525            2       True   \n3                 0.001787           7.317618            3       True   \n4                 1.693198           1.236228            2       True   \n5                 0.279920          90.261430            2       True   \n6                 0.126046         550.849767            2       True   \n7                 0.323279          22.723590            2       True   \n8                 0.558985          46.572398            2       True   \n9                 0.324929          94.475197            2       True   \n10                0.004602           7.085810            2       True   \n11                0.771602           8.660446            1       True   \n12                0.167202          93.352953            1       True   \n13                2.567961          26.217775            2       True   \n14                3.428351          11.004182            1       True   \n15                4.740445          26.699265            1       True   \n16                0.582430           1.547200            1       True   \n17                1.949258          20.234462            1       True   \n18                0.486018          61.145562            1       True   \n19                0.772316          11.528171            1       True   \n20                4.204147          40.664564            1       True   \n21                0.075096          60.623348            1       True   \n22                0.813335          14.735926            1       True   \n23                0.167994         193.077350            1       True   \n24                0.410296          35.582204            1       True   \n25                0.080627          81.887159            1       True   \n26                0.204384          18.767445            1       True   \n27                0.110940         468.307663            1       True   \n28                0.450151           1.594295            1       True   \n29                0.111116          74.177878            1       True   \n30                0.310577           1.858434            1       True   \n31                3.233672          16.821245            1       True   \n32                0.084572         104.314416            1       True   \n33                0.420395           0.935569            1       True   \n34                0.466232           1.429103            1       True   \n35                0.110171           9.228248            1       True   \n36                0.428307           0.980802            1       True   \n37                0.116740         105.966872            1       True   \n38               21.551668          55.833047            1       True   \n39                6.489633          25.191653            1       True   \n40                0.118833          82.006149            1       True   \n41                0.226510          28.075688            1       True   \n42                0.033397           0.018247            1       True   \n43                0.029563           0.018913            1       True   \n\n    fit_order  \n0          41  \n1          38  \n2          37  \n3          44  \n4          40  \n5          36  \n6          39  \n7          34  \n8          35  \n9          42  \n10         33  \n11          5  \n12         20  \n13         43  \n14         31  \n15         16  \n16         22  \n17         13  \n18         17  \n19         29  \n20         21  \n21         14  \n22         11  \n23         18  \n24         28  \n25          8  \n26          3  \n27         25  \n28          7  \n29         15  \n30         26  \n31          4  \n32         23  \n33         10  \n34          6  \n35         24  \n36          9  \n37         30  \n38         19  \n39         27  \n40         12  \n41         32  \n42          2  \n43          1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ExtraTreesEntr_BAG_L2</td>\n      <td>0.9556</td>\n      <td>0.955729</td>\n      <td>accuracy</td>\n      <td>51.280732</td>\n      <td>54.951336</td>\n      <td>1657.623791</td>\n      <td>0.239503</td>\n      <td>1.805358</td>\n      <td>1.355332</td>\n      <td>2</td>\n      <td>True</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RandomForestEntr_BAG_L2</td>\n      <td>0.9554</td>\n      <td>0.957031</td>\n      <td>accuracy</td>\n      <td>51.227826</td>\n      <td>54.938805</td>\n      <td>1659.172585</td>\n      <td>0.186597</td>\n      <td>1.792827</td>\n      <td>2.904126</td>\n      <td>2</td>\n      <td>True</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForestGini_BAG_L2</td>\n      <td>0.9552</td>\n      <td>0.957532</td>\n      <td>accuracy</td>\n      <td>51.309514</td>\n      <td>54.854422</td>\n      <td>1659.632984</td>\n      <td>0.268285</td>\n      <td>1.708444</td>\n      <td>3.364525</td>\n      <td>2</td>\n      <td>True</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>WeightedEnsemble_L3</td>\n      <td>0.9548</td>\n      <td>0.960938</td>\n      <td>accuracy</td>\n      <td>57.052236</td>\n      <td>59.865204</td>\n      <td>1813.271291</td>\n      <td>0.005906</td>\n      <td>0.001787</td>\n      <td>7.317618</td>\n      <td>3</td>\n      <td>True</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ExtraTreesGini_BAG_L2</td>\n      <td>0.9544</td>\n      <td>0.956631</td>\n      <td>accuracy</td>\n      <td>51.262278</td>\n      <td>54.839176</td>\n      <td>1657.504687</td>\n      <td>0.221049</td>\n      <td>1.693198</td>\n      <td>1.236228</td>\n      <td>2</td>\n      <td>True</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LightGBM_BAG_L2</td>\n      <td>0.9544</td>\n      <td>0.957833</td>\n      <td>accuracy</td>\n      <td>51.532950</td>\n      <td>53.425898</td>\n      <td>1746.529889</td>\n      <td>0.491721</td>\n      <td>0.279920</td>\n      <td>90.261430</td>\n      <td>2</td>\n      <td>True</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>CatBoost_BAG_L2</td>\n      <td>0.9542</td>\n      <td>0.958233</td>\n      <td>accuracy</td>\n      <td>51.230510</td>\n      <td>53.272024</td>\n      <td>2207.118226</td>\n      <td>0.189281</td>\n      <td>0.126046</td>\n      <td>550.849767</td>\n      <td>2</td>\n      <td>True</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NeuralNetFastAI_BAG_L2</td>\n      <td>0.9540</td>\n      <td>0.959836</td>\n      <td>accuracy</td>\n      <td>51.939987</td>\n      <td>53.469257</td>\n      <td>1678.992049</td>\n      <td>0.898758</td>\n      <td>0.323279</td>\n      <td>22.723590</td>\n      <td>2</td>\n      <td>True</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>LightGBMXT_BAG_L2</td>\n      <td>0.9538</td>\n      <td>0.957632</td>\n      <td>accuracy</td>\n      <td>51.746619</td>\n      <td>53.704963</td>\n      <td>1702.840857</td>\n      <td>0.705390</td>\n      <td>0.558985</td>\n      <td>46.572398</td>\n      <td>2</td>\n      <td>True</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>XGBoost_BAG_L2</td>\n      <td>0.9536</td>\n      <td>0.958934</td>\n      <td>accuracy</td>\n      <td>51.974730</td>\n      <td>53.470906</td>\n      <td>1750.743656</td>\n      <td>0.933501</td>\n      <td>0.324929</td>\n      <td>94.475197</td>\n      <td>2</td>\n      <td>True</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>0.9518</td>\n      <td>0.958634</td>\n      <td>accuracy</td>\n      <td>6.098422</td>\n      <td>5.051507</td>\n      <td>385.386959</td>\n      <td>0.007404</td>\n      <td>0.004602</td>\n      <td>7.085810</td>\n      <td>2</td>\n      <td>True</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>LightGBM_BAG_L1</td>\n      <td>0.9480</td>\n      <td>0.948718</td>\n      <td>accuracy</td>\n      <td>0.957437</td>\n      <td>0.771602</td>\n      <td>8.660446</td>\n      <td>0.957437</td>\n      <td>0.771602</td>\n      <td>8.660446</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>NeuralNetTorch_r22_BAG_L1</td>\n      <td>0.9474</td>\n      <td>0.944712</td>\n      <td>accuracy</td>\n      <td>0.210832</td>\n      <td>0.167202</td>\n      <td>93.352953</td>\n      <td>0.210832</td>\n      <td>0.167202</td>\n      <td>93.352953</td>\n      <td>1</td>\n      <td>True</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>NeuralNetTorch_BAG_L2</td>\n      <td>0.9470</td>\n      <td>0.951222</td>\n      <td>accuracy</td>\n      <td>54.759190</td>\n      <td>55.713939</td>\n      <td>1682.486234</td>\n      <td>3.717961</td>\n      <td>2.567961</td>\n      <td>26.217775</td>\n      <td>2</td>\n      <td>True</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>LightGBM_r130_BAG_L1</td>\n      <td>0.9468</td>\n      <td>0.947115</td>\n      <td>accuracy</td>\n      <td>2.941569</td>\n      <td>3.428351</td>\n      <td>11.004182</td>\n      <td>2.941569</td>\n      <td>3.428351</td>\n      <td>11.004182</td>\n      <td>1</td>\n      <td>True</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>LightGBM_r131_BAG_L1</td>\n      <td>0.9468</td>\n      <td>0.947516</td>\n      <td>accuracy</td>\n      <td>4.137506</td>\n      <td>4.740445</td>\n      <td>26.699265</td>\n      <td>4.137506</td>\n      <td>4.740445</td>\n      <td>26.699265</td>\n      <td>1</td>\n      <td>True</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>ExtraTrees_r42_BAG_L1</td>\n      <td>0.9464</td>\n      <td>0.944411</td>\n      <td>accuracy</td>\n      <td>0.344166</td>\n      <td>0.582430</td>\n      <td>1.547200</td>\n      <td>0.344166</td>\n      <td>0.582430</td>\n      <td>1.547200</td>\n      <td>1</td>\n      <td>True</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>LightGBMLarge_BAG_L1</td>\n      <td>0.9460</td>\n      <td>0.945212</td>\n      <td>accuracy</td>\n      <td>1.883965</td>\n      <td>1.949258</td>\n      <td>20.234462</td>\n      <td>1.883965</td>\n      <td>1.949258</td>\n      <td>20.234462</td>\n      <td>1</td>\n      <td>True</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>NeuralNetFastAI_r191_BAG_L1</td>\n      <td>0.9454</td>\n      <td>0.949820</td>\n      <td>accuracy</td>\n      <td>0.845418</td>\n      <td>0.486018</td>\n      <td>61.145562</td>\n      <td>0.845418</td>\n      <td>0.486018</td>\n      <td>61.145562</td>\n      <td>1</td>\n      <td>True</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>XGBoost_r89_BAG_L1</td>\n      <td>0.9452</td>\n      <td>0.945012</td>\n      <td>accuracy</td>\n      <td>1.372199</td>\n      <td>0.772316</td>\n      <td>11.528171</td>\n      <td>1.372199</td>\n      <td>0.772316</td>\n      <td>11.528171</td>\n      <td>1</td>\n      <td>True</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>XGBoost_r33_BAG_L1</td>\n      <td>0.9452</td>\n      <td>0.943810</td>\n      <td>accuracy</td>\n      <td>3.751048</td>\n      <td>4.204147</td>\n      <td>40.664564</td>\n      <td>3.751048</td>\n      <td>4.204147</td>\n      <td>40.664564</td>\n      <td>1</td>\n      <td>True</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>CatBoost_r177_BAG_L1</td>\n      <td>0.9442</td>\n      <td>0.943009</td>\n      <td>accuracy</td>\n      <td>0.141376</td>\n      <td>0.075096</td>\n      <td>60.623348</td>\n      <td>0.141376</td>\n      <td>0.075096</td>\n      <td>60.623348</td>\n      <td>1</td>\n      <td>True</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>XGBoost_BAG_L1</td>\n      <td>0.9438</td>\n      <td>0.946214</td>\n      <td>accuracy</td>\n      <td>1.351704</td>\n      <td>0.813335</td>\n      <td>14.735926</td>\n      <td>1.351704</td>\n      <td>0.813335</td>\n      <td>14.735926</td>\n      <td>1</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>CatBoost_r9_BAG_L1</td>\n      <td>0.9434</td>\n      <td>0.942909</td>\n      <td>accuracy</td>\n      <td>0.366138</td>\n      <td>0.167994</td>\n      <td>193.077350</td>\n      <td>0.366138</td>\n      <td>0.167994</td>\n      <td>193.077350</td>\n      <td>1</td>\n      <td>True</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>NeuralNetFastAI_r145_BAG_L1</td>\n      <td>0.9434</td>\n      <td>0.947216</td>\n      <td>accuracy</td>\n      <td>1.162542</td>\n      <td>0.410296</td>\n      <td>35.582204</td>\n      <td>1.162542</td>\n      <td>0.410296</td>\n      <td>35.582204</td>\n      <td>1</td>\n      <td>True</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>CatBoost_BAG_L1</td>\n      <td>0.9428</td>\n      <td>0.942007</td>\n      <td>accuracy</td>\n      <td>0.139978</td>\n      <td>0.080627</td>\n      <td>81.887159</td>\n      <td>0.139978</td>\n      <td>0.080627</td>\n      <td>81.887159</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>NeuralNetFastAI_BAG_L1</td>\n      <td>0.9424</td>\n      <td>0.944511</td>\n      <td>accuracy</td>\n      <td>0.548068</td>\n      <td>0.204384</td>\n      <td>18.767445</td>\n      <td>0.548068</td>\n      <td>0.204384</td>\n      <td>18.767445</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>CatBoost_r13_BAG_L1</td>\n      <td>0.9422</td>\n      <td>0.939904</td>\n      <td>accuracy</td>\n      <td>0.331450</td>\n      <td>0.110940</td>\n      <td>468.307663</td>\n      <td>0.331450</td>\n      <td>0.110940</td>\n      <td>468.307663</td>\n      <td>1</td>\n      <td>True</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>RandomForestEntr_BAG_L1</td>\n      <td>0.9414</td>\n      <td>0.942708</td>\n      <td>accuracy</td>\n      <td>0.226238</td>\n      <td>0.450151</td>\n      <td>1.594295</td>\n      <td>0.226238</td>\n      <td>0.450151</td>\n      <td>1.594295</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>NeuralNetTorch_r79_BAG_L1</td>\n      <td>0.9414</td>\n      <td>0.944111</td>\n      <td>accuracy</td>\n      <td>0.277757</td>\n      <td>0.111116</td>\n      <td>74.177878</td>\n      <td>0.277757</td>\n      <td>0.111116</td>\n      <td>74.177878</td>\n      <td>1</td>\n      <td>True</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>RandomForest_r195_BAG_L1</td>\n      <td>0.9402</td>\n      <td>0.941607</td>\n      <td>accuracy</td>\n      <td>0.291170</td>\n      <td>0.310577</td>\n      <td>1.858434</td>\n      <td>0.291170</td>\n      <td>0.310577</td>\n      <td>1.858434</td>\n      <td>1</td>\n      <td>True</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>LightGBMXT_BAG_L1</td>\n      <td>0.9396</td>\n      <td>0.940605</td>\n      <td>accuracy</td>\n      <td>2.863546</td>\n      <td>3.233672</td>\n      <td>16.821245</td>\n      <td>2.863546</td>\n      <td>3.233672</td>\n      <td>16.821245</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>CatBoost_r137_BAG_L1</td>\n      <td>0.9376</td>\n      <td>0.937600</td>\n      <td>accuracy</td>\n      <td>0.197300</td>\n      <td>0.084572</td>\n      <td>104.314416</td>\n      <td>0.197300</td>\n      <td>0.084572</td>\n      <td>104.314416</td>\n      <td>1</td>\n      <td>True</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>ExtraTreesEntr_BAG_L1</td>\n      <td>0.9370</td>\n      <td>0.938802</td>\n      <td>accuracy</td>\n      <td>0.337598</td>\n      <td>0.420395</td>\n      <td>0.935569</td>\n      <td>0.337598</td>\n      <td>0.420395</td>\n      <td>0.935569</td>\n      <td>1</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>RandomForestGini_BAG_L1</td>\n      <td>0.9366</td>\n      <td>0.939103</td>\n      <td>accuracy</td>\n      <td>0.319590</td>\n      <td>0.466232</td>\n      <td>1.429103</td>\n      <td>0.319590</td>\n      <td>0.466232</td>\n      <td>1.429103</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>NeuralNetFastAI_r102_BAG_L1</td>\n      <td>0.9354</td>\n      <td>0.935897</td>\n      <td>accuracy</td>\n      <td>0.250275</td>\n      <td>0.110171</td>\n      <td>9.228248</td>\n      <td>0.250275</td>\n      <td>0.110171</td>\n      <td>9.228248</td>\n      <td>1</td>\n      <td>True</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>ExtraTreesGini_BAG_L1</td>\n      <td>0.9354</td>\n      <td>0.939103</td>\n      <td>accuracy</td>\n      <td>0.266671</td>\n      <td>0.428307</td>\n      <td>0.980802</td>\n      <td>0.266671</td>\n      <td>0.428307</td>\n      <td>0.980802</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>NeuralNetTorch_r30_BAG_L1</td>\n      <td>0.9352</td>\n      <td>0.935397</td>\n      <td>accuracy</td>\n      <td>0.265321</td>\n      <td>0.116740</td>\n      <td>105.966872</td>\n      <td>0.265321</td>\n      <td>0.116740</td>\n      <td>105.966872</td>\n      <td>1</td>\n      <td>True</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>LightGBM_r96_BAG_L1</td>\n      <td>0.9352</td>\n      <td>0.935797</td>\n      <td>accuracy</td>\n      <td>18.119450</td>\n      <td>21.551668</td>\n      <td>55.833047</td>\n      <td>18.119450</td>\n      <td>21.551668</td>\n      <td>55.833047</td>\n      <td>1</td>\n      <td>True</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>LightGBM_r188_BAG_L1</td>\n      <td>0.9332</td>\n      <td>0.933794</td>\n      <td>accuracy</td>\n      <td>6.597619</td>\n      <td>6.489633</td>\n      <td>25.191653</td>\n      <td>6.597619</td>\n      <td>6.489633</td>\n      <td>25.191653</td>\n      <td>1</td>\n      <td>True</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>NeuralNetTorch_BAG_L1</td>\n      <td>0.9328</td>\n      <td>0.935998</td>\n      <td>accuracy</td>\n      <td>0.182663</td>\n      <td>0.118833</td>\n      <td>82.006149</td>\n      <td>0.182663</td>\n      <td>0.118833</td>\n      <td>82.006149</td>\n      <td>1</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>NeuralNetTorch_r86_BAG_L1</td>\n      <td>0.9320</td>\n      <td>0.929788</td>\n      <td>accuracy</td>\n      <td>0.310909</td>\n      <td>0.226510</td>\n      <td>28.075688</td>\n      <td>0.310909</td>\n      <td>0.226510</td>\n      <td>28.075688</td>\n      <td>1</td>\n      <td>True</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>KNeighborsDist_BAG_L1</td>\n      <td>0.2238</td>\n      <td>0.219451</td>\n      <td>accuracy</td>\n      <td>0.025430</td>\n      <td>0.033397</td>\n      <td>0.018247</td>\n      <td>0.025430</td>\n      <td>0.033397</td>\n      <td>0.018247</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>KNeighborsUnif_BAG_L1</td>\n      <td>0.2190</td>\n      <td>0.208534</td>\n      <td>accuracy</td>\n      <td>0.024295</td>\n      <td>0.029563</td>\n      <td>0.018913</td>\n      <td>0.024295</td>\n      <td>0.029563</td>\n      <td>0.018913</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data)"
   ],
   "id": "ef12b69d52abeb4a"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-da0PXvpD96"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this quickstart tutorial we saw AutoGluon's basic fit and predict functionality using `TabularDataset` and `TabularPredictor`. AutoGluon simplifies the model training process by not requiring feature engineering or model hyperparameter tuning. Check out the in-depth tutorials to learn more about AutoGluon's other features like customizing the training and prediction steps or extending AutoGluon with custom feature generators, models, or metrics."
   ],
   "id": "eb52ad3e03914f45"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5ad4fd34453ee331"
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython"
  },
  "kernelspec": {
   "name": "venv_ag_310",
   "language": "python",
   "display_name": "venv_ag_310"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
