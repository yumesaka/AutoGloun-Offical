{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGluon Tabular - Quick Start\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/autogluon/autogluon/blob/master/docs/tutorials/tabular/tabular-quick-start.ipynb)\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/autogluon/autogluon/blob/master/docs/tutorials/tabular/tabular-quick-start.ipynb)\n",
    "\n",
    "In this tutorial, we will see how to use AutoGluon's `TabularPredictor` to predict the values of a target column based on the other columns in a tabular dataset.\n",
    "\n",
    "Begin by making sure AutoGluon is installed, and then import AutoGluon's `TabularDataset` and `TabularPredictor`. We will use the former to load data and the latter to train models and make predictions. "
   ],
   "id": "688ad0938f1752be"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-output"
    ],
    "ExecuteTime": {
     "end_time": "2023-12-26T10:17:27.818722Z",
     "start_time": "2023-12-26T10:17:27.809794Z"
    }
   },
   "outputs": [],
   "source": [
    "# !python -m pip install --upgrade pip\n",
    "# !python -m pip install autogluon"
   ],
   "id": "3804b5c7d11a9891"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T10:17:45.640717Z",
     "start_time": "2023-12-26T10:17:42.119993Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elnath/anaconda3/envs/venv_ag_310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ],
   "id": "6be8fb99702bf01e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Data"
   ],
   "id": "6bfd71b3b65eb529"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial we will use a dataset from the cover story of [Nature issue 7887](https://www.nature.com/nature/volumes/600/issues/7887): [AI-guided intuition for math theorems](https://www.nature.com/articles/s41586-021-04086-x.pdf). The goal is to predict a knot's signature based on its properties. We sampled 10K training and 5K test examples from the [original data](https://github.com/deepmind/mathematics_conjectures/blob/main/knot_theory.ipynb). The sampled dataset make this tutorial run quickly, but AutoGluon can handle the full dataset if desired.\n",
    "\n",
    "We load this dataset directly from a URL. AutoGluon's `TabularDataset` is a subclass of pandas [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html), so any `DataFrame` methods can be used on `TabularDataset` as well."
   ],
   "id": "c8222fcc3487344c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T10:18:11.453412Z",
     "start_time": "2023-12-26T10:18:11.033757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0  chern_simons  cusp_volume  hyperbolic_adjoint_torsion_degree  \\\n0       70746      0.090530    12.226322                                  0   \n1      240827      0.232453    13.800773                                  0   \n2      155659     -0.144099    14.761030                                  0   \n3      239963     -0.171668    13.738019                                  0   \n4       90504      0.235188    15.896359                                  0   \n\n   hyperbolic_torsion_degree  injectivity_radius  longitudinal_translation  \\\n0                         10            0.507756                 10.685555   \n1                         14            0.413645                 10.453156   \n2                         14            0.436928                 13.405199   \n3                         22            0.249481                 27.819496   \n4                         10            0.389329                 15.330971   \n\n   meridinal_translation_imag  meridinal_translation_real  \\\n0                    1.144192                   -0.519157   \n1                    1.320249                   -0.158522   \n2                    1.101142                    0.768894   \n3                    0.493827                   -1.188718   \n4                    1.036879                    0.722828   \n\n   short_geodesic_imag_part  short_geodesic_real_part  Symmetry_0  \\\n0                 -2.760601                  1.015512         0.0   \n1                 -3.013258                  0.827289         0.0   \n2                  2.233106                  0.873856         0.0   \n3                 -2.042771                  0.498961         0.0   \n4                 -3.056138                  0.778658         0.0   \n\n   Symmetry_D3  Symmetry_D4  Symmetry_D6  Symmetry_D8  Symmetry_Z/2 + Z/2  \\\n0          0.0          0.0          0.0          0.0                 1.0   \n1          0.0          0.0          0.0          0.0                 1.0   \n2          0.0          0.0          0.0          0.0                 0.0   \n3          0.0          0.0          0.0          0.0                 0.0   \n4          0.0          0.0          0.0          0.0                 0.0   \n\n      volume  signature  \n0  11.393225         -2  \n1  12.742782          0  \n2  15.236505          2  \n3  17.279890         -8  \n4  16.749298          4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>chern_simons</th>\n      <th>cusp_volume</th>\n      <th>hyperbolic_adjoint_torsion_degree</th>\n      <th>hyperbolic_torsion_degree</th>\n      <th>injectivity_radius</th>\n      <th>longitudinal_translation</th>\n      <th>meridinal_translation_imag</th>\n      <th>meridinal_translation_real</th>\n      <th>short_geodesic_imag_part</th>\n      <th>short_geodesic_real_part</th>\n      <th>Symmetry_0</th>\n      <th>Symmetry_D3</th>\n      <th>Symmetry_D4</th>\n      <th>Symmetry_D6</th>\n      <th>Symmetry_D8</th>\n      <th>Symmetry_Z/2 + Z/2</th>\n      <th>volume</th>\n      <th>signature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>70746</td>\n      <td>0.090530</td>\n      <td>12.226322</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.507756</td>\n      <td>10.685555</td>\n      <td>1.144192</td>\n      <td>-0.519157</td>\n      <td>-2.760601</td>\n      <td>1.015512</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>11.393225</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>240827</td>\n      <td>0.232453</td>\n      <td>13.800773</td>\n      <td>0</td>\n      <td>14</td>\n      <td>0.413645</td>\n      <td>10.453156</td>\n      <td>1.320249</td>\n      <td>-0.158522</td>\n      <td>-3.013258</td>\n      <td>0.827289</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>12.742782</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>155659</td>\n      <td>-0.144099</td>\n      <td>14.761030</td>\n      <td>0</td>\n      <td>14</td>\n      <td>0.436928</td>\n      <td>13.405199</td>\n      <td>1.101142</td>\n      <td>0.768894</td>\n      <td>2.233106</td>\n      <td>0.873856</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>15.236505</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>239963</td>\n      <td>-0.171668</td>\n      <td>13.738019</td>\n      <td>0</td>\n      <td>22</td>\n      <td>0.249481</td>\n      <td>27.819496</td>\n      <td>0.493827</td>\n      <td>-1.188718</td>\n      <td>-2.042771</td>\n      <td>0.498961</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>17.279890</td>\n      <td>-8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>90504</td>\n      <td>0.235188</td>\n      <td>15.896359</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.389329</td>\n      <td>15.330971</td>\n      <td>1.036879</td>\n      <td>0.722828</td>\n      <td>-3.056138</td>\n      <td>0.778658</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>16.749298</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = 'https://raw.githubusercontent.com/mli/ag-docs/main/knot_theory/'\n",
    "train_data = TabularDataset(f'{data_url}train.csv')\n",
    "train_data.head()"
   ],
   "id": "5ec75ca26e70a2b9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our targets are stored in the \"signature\" column, which has 18 unique integers. Even though pandas didn't correctly recognize this data type as categorical, AutoGluon will fix this issue.\n"
   ],
   "id": "f473c60134d9d320"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T10:18:11.853049Z",
     "start_time": "2023-12-26T10:18:11.845984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    10000.000000\nmean        -0.022000\nstd          3.025166\nmin        -12.000000\n25%         -2.000000\n50%          0.000000\n75%          2.000000\nmax         12.000000\nName: signature, dtype: float64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = 'signature'\n",
    "train_data[label].describe()"
   ],
   "id": "a3be45e1d1ad99bf"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We now construct a `TabularPredictor` by specifying the label column name and then train on the dataset with `TabularPredictor.fit()`. We don't need to specify any other parameters. AutoGluon will recognize this is a multi-class classification task, perform automatic feature engineering, train multiple models, and then ensemble the models to create the final predictor. "
   ],
   "id": "c514291f69f019ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ],
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-26T10:18:12.926672Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231226_101812\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231226_101812\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 23.2.0: Wed Nov 15 21:54:10 PST 2023; root:xnu-10002.61.3~2/RELEASE_X86_64\n",
      "CPU Count:          16\n",
      "Memory Avail:       38.48 GB / 64.00 GB (60.1%)\n",
      "Disk Space Avail:   471.49 GB / 931.55 GB (50.6%)\n",
      "===================================================\n",
      "Train Data Rows:    10000\n",
      "Train Data Columns: 18\n",
      "Label Column:       signature\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\tFirst 10 (of 13) unique label values:  [-2, 0, 2, -8, 4, -4, -6, 8, 6, 10]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 9 out of 13 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9984\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    39401.91 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.37 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['Symmetry_D8']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['chern_simons', 'cusp_volume', 'injectivity_radius', 'longitudinal_translation', 'meridinal_translation_imag', ...]\n",
      "\t\t('int', [])   :  3 | ['Unnamed: 0', 'hyperbolic_adjoint_torsion_degree', 'hyperbolic_torsion_degree']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 9 | ['chern_simons', 'cusp_volume', 'injectivity_radius', 'longitudinal_translation', 'meridinal_translation_imag', ...]\n",
      "\t\t('int', [])       : 3 | ['Unnamed: 0', 'hyperbolic_adjoint_torsion_degree', 'hyperbolic_torsion_degree']\n",
      "\t\t('int', ['bool']) : 5 | ['Symmetry_0', 'Symmetry_D3', 'Symmetry_D4', 'Symmetry_D6', 'Symmetry_Z/2 + Z/2']\n",
      "\t0.1s = Fit runtime\n",
      "\t17 features in original data used to generate 17 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.96 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8985, Val Rows: 999\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.2232\t = Validation score   (accuracy)\n",
      "\t4.6s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.2132\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.9449\t = Validation score   (accuracy)\n",
      "\t7.96s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.9459\t = Validation score   (accuracy)\n",
      "\t3.3s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.956\t = Validation score   (accuracy)\n",
      "\t2.22s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.9439\t = Validation score   (accuracy)\n",
      "\t1.31s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9489\t = Validation score   (accuracy)\n",
      "\t1.23s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label).fit(train_data)"
   ],
   "id": "6100cf7e354377f8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model fitting should take a few minutes or less depending on your CPU. You can make training faster by specifying the `time_limit` argument. For example, `fit(..., time_limit=60)` will stop training after 60 seconds. Higher time limits will generally result in better prediction performance, and excessively low time limits will prevent AutoGluon from training and ensembling a reasonable set of models.\n",
    "\n"
   ],
   "id": "faf153c1b05d927d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "Once we have a predictor that is fit on the training dataset, we can load a separate set of data to use for prediction and evaulation."
   ],
   "id": "4290ac680b47be14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "test_data = TabularDataset(f'{data_url}test.csv')\n",
    "\n",
    "y_pred = predictor.predict(test_data.drop(columns=[label]))\n",
    "y_pred.head()"
   ],
   "id": "84c9a96672acfb47"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We can evaluate the predictor on the test dataset using the `evaluate()` function, which measures how well our predictor performs on data that was not used for fitting the models."
   ],
   "id": "8db04e1bbbeeb9f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "predictor.evaluate(test_data, silent=True)"
   ],
   "id": "ec3771820cd60edf"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoGluon's `TabularPredictor` also provides the `leaderboard()` function, which allows us to evaluate the performance of each individual trained model on the test data."
   ],
   "id": "4f0b5327828b7bd1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "predictor.leaderboard(test_data)"
   ],
   "id": "ef12b69d52abeb4a"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-da0PXvpD96"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this quickstart tutorial we saw AutoGluon's basic fit and predict functionality using `TabularDataset` and `TabularPredictor`. AutoGluon simplifies the model training process by not requiring feature engineering or model hyperparameter tuning. Check out the in-depth tutorials to learn more about AutoGluon's other features like customizing the training and prediction steps or extending AutoGluon with custom feature generators, models, or metrics."
   ],
   "id": "eb52ad3e03914f45"
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython"
  },
  "kernelspec": {
   "name": "venv_ag_310",
   "language": "python",
   "display_name": "venv_ag_310"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
